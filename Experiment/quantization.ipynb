{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "quantization.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C1BK0bY5Tzh",
        "outputId": "b1b41a4c-83a3-4c2f-b098-68431dd1c452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# clone github repository setup\n",
        "from os.path import join\n",
        "from google.colab import drive\n",
        "\n",
        "# path to your project on Google Drive\n",
        "MY_GOOGLE_DRIVE_PATH = 'My Drive/Capstone Project'\n",
        "ROOT = '/content/gdrive/'\n",
        "drive.mount(ROOT)\n",
        "\n",
        "# replace with your Github token, username, repo\n",
        "GIT_TOKEN = '4f61cb936944e66abd13e7e809e199ee3a378fae'\n",
        "GIT_USERNAME = 'mohitgulla' \n",
        "GIT_REPOSITORY = 'Edge'\n",
        "\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
        "print('PROJECT_PATH: ', PROJECT_PATH)   \n",
        "\n",
        "# In case we haven't created the folder already\n",
        "!mkdir '{PROJECT_PATH}'    \n",
        "\n",
        "GIT_PATH = 'https://' + GIT_TOKEN + '@github.com/' + GIT_USERNAME + '/' + GIT_REPOSITORY + '.git'\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "PROJECT_PATH:  /content/gdrive/My Drive/Capstone Project\n",
            "mkdir: cannot create directory ‘/content/gdrive/My Drive/Capstone Project’: File exists\n",
            "GIT_PATH:  https://4f61cb936944e66abd13e7e809e199ee3a378fae@github.com/mohitgulla/Edge.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJxcMLqv5a3q"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import make_column_transformer"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obqhMn9nQsck"
      },
      "source": [
        "**Quantization Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdkPm3qK_YTH"
      },
      "source": [
        "**Experiment with Artifical Neural Networks (ANNs) - Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlQb_KMq_rxu",
        "outputId": "9e45fdf3-253b-49db-fe89-910f001f6cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# import churn and telescope datasets\n",
        "data_dir = ROOT + MY_GOOGLE_DRIVE_PATH + '/Edge/data/'\n",
        "\n",
        "churn = pd.read_csv(data_dir + 'churn.csv')\n",
        "churn.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
        "\n",
        "telescope = pd.read_table(data_dir + 'telescope.dat', header=None, delimiter=',')\n",
        "telescope.columns = ['FLength', 'FWidth', 'FSize', 'FConc', 'FConc1', 'FAsym', \n",
        "                     'FM3Long', 'FM3Trans', 'FAlpha', 'FDist', 'Class']\n",
        "\n",
        "print('Shape - Churn: {} & Telescope: {}'.format(churn.shape, telescope.shape))\n",
        "\n",
        "# preprocess churn & telescope data, convert numpy to tensor\n",
        "preprocess = make_column_transformer(\n",
        "    (OneHotEncoder(), ['Geography', 'Gender']), remainder = 'passthrough')\n",
        "data = preprocess.fit_transform(churn.iloc[:, :-1])\n",
        "target = np.array(churn.iloc[:, -1])\n",
        "print('\\nClass Distribution - Churn:', Counter(target))\n",
        "churn = {'data': torch.from_numpy(data), 'target': torch.from_numpy(target)}\n",
        "\n",
        "data = np.array(telescope.iloc[:, :-1])\n",
        "target = LabelEncoder().fit_transform(telescope.Class)\n",
        "print('\\nClass Distribution - Telescope:', Counter(target))\n",
        "telescope = {'data': torch.from_numpy(data), 'target': torch.from_numpy(target)}"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape - Churn: (10000, 11) & Telescope: (19020, 11)\n",
            "\n",
            "Class Distribution - Churn: Counter({0: 7963, 1: 2037})\n",
            "\n",
            "Class Distribution - Telescope: Counter({0: 12332, 1: 6688})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p49HKp4sMe_Y"
      },
      "source": [
        ""
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLrjWO-s_l5Y"
      },
      "source": [
        "**Experiment with Artifical Neural Networks (ANNs) - Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCnsKgFh_n0e"
      },
      "source": [
        "**Experiment with Convolutional Neural Networks (CNNs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA34zsXoQy8z"
      },
      "source": [
        "**Results & Analysis**"
      ]
    }
  ]
}