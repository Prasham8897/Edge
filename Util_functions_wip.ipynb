{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Util_functions_wip.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4uHdHOuKWmI",
        "outputId": "cdcd2cb4-092d-4eb6-8f3e-85c6881210b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "ROOT=\"/content/drive\"\n",
        "print(ROOT)\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiHhXVtSy0DR",
        "outputId": "6c2d4a87-6aff-42c6-e13d-e089dbba3e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My Drive/GE Edge Capstone 2020/Edge"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/GE Edge Capstone 2020/Edge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NQknHXHNLjS"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import norm"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "952avilUafSi"
      },
      "source": [
        "**Main Quantization Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDimbAACNH_Y"
      },
      "source": [
        "def quantization (model_name, method ='all'):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model_object = 'model_artifacts/' + model_name\n",
        "  results = pd.DataFrame(columns=['model', 'method', 'precision', 'model_artifact',\n",
        "                                'train_loss', 'train_acc', 'test_loss', 'test_acc'])\n",
        "\n",
        "  precision = [24,20,16,12,8,4]\n",
        "  unique_val_method=['uniform_range','uniform_range_IQR', 'prior_normal']\n",
        "\n",
        "  #Stochastic Rounding\n",
        "  if method == 'stochastic_rounding' or method == 'all':\n",
        "    for i in unique_val_method:\n",
        "      print(i)\n",
        "      for p in precision:\n",
        "        print(p)\n",
        "        model = torch.load(model_object, map_location=torch.device(device))\n",
        "        weights=dict()\n",
        "        for name, params in model.named_parameters():\n",
        "          weights[name] = params.clone()\n",
        "        unique_values=unique_value_generator(weights,p,approach=i) #Generates unique values per layer. Returns unique values of all layers\n",
        "        for w in weights:\n",
        "          print(w)\n",
        "          weights[w]=stochastic_quant(weights[w], unique_values[w])\n",
        "        for name, params in model.named_parameters():\n",
        "          params.data.copy_(weights[name])\n",
        "\n",
        "        results = results.append({'model': model_name, 'method': 'mid-rise', 'precision': p, 'model_artifact': model},\n",
        "                                  ignore_index=True)\n",
        "        print('Results appended :', i, '\\t',p)\n",
        "\n",
        "\n",
        "  #Normal Rounding\n",
        "  if method == 'normal_rounding' or method == 'all':\n",
        "    for i in unique_val_method:\n",
        "      for p in precision:\n",
        "        print(p)\n",
        "        model = torch.load(model_object, map_location=torch.device(device))\n",
        "        weights=dict()\n",
        "        for name, params in model.named_parameters():\n",
        "          weights[name] = params.clone()\n",
        "        unique_values=unique_value_generator(weights,p,approach=i) #Generates unique values per layer. Returns unique values of all layers\n",
        "        for w in weights:\n",
        "          print(w)\n",
        "          weights[w]=rounding_quant(weights[w], unique_values[w])\n",
        "        for name, params in model.named_parameters():\n",
        "          params.data.copy_(weights[name])\n",
        "\n",
        "        results = results.append({'model': model_name, 'method': 'mid-rise', 'precision': p, 'model_artifact': model},\n",
        "                                  ignore_index=True)\n",
        "        \n",
        "\n",
        "  # mid-rise quantization\n",
        "  if method == 'mid-rise' or method == 'all':\n",
        "    for p in precision:\n",
        "        weights = dict()\n",
        "        model = torch.load(model_object, map_location=torch.device(device))\n",
        "\n",
        "        for name, params in model.named_parameters():\n",
        "            weights[name] = params.clone()\n",
        "        for w in weights:\n",
        "            if len(weights[w]) == 1:\n",
        "                delta = weights[w] / 2**p\n",
        "            else:\n",
        "                delta = (torch.max(weights[w]) - torch.min(weights[w])) / 2**p\n",
        "            weights[w] = delta * (torch.floor(weights[w]/delta) + 0.5)\n",
        "        for name, params in model.named_parameters():\n",
        "            params.data.copy_(weights[name])\n",
        "\n",
        "        results = results.append(\n",
        "            {'model': model_name, 'method': 'mid-rise', 'precision': p, 'model_artifact': model},\n",
        "            ignore_index=True\n",
        "        )\n",
        "\n",
        "  # mid-rise quantization + IQR\n",
        "  if method == 'mid-rise_iqr' or method == 'all':\n",
        "    for p in precision:\n",
        "        weights = dict()\n",
        "        model = torch.load(model_object, map_location=torch.device(device))\n",
        "\n",
        "        for name, params in model.named_parameters():\n",
        "            weights[name] = params.clone()\n",
        "        for w in weights:\n",
        "            if len(weights[w]) == 1:\n",
        "                delta = weights[w] / 2**p\n",
        "            else:\n",
        "                weights_w=np.sort(weights[w].detach().numpy())\n",
        "                Q1 = np.percentile(weights_w, 25, interpolation = 'midpoint')  \n",
        "                Q2 = np.percentile(weights_w, 50, interpolation = 'midpoint')  \n",
        "                Q3 = np.percentile(weights_w, 75, interpolation = 'midpoint')  \n",
        "                IQR=Q3-Q1\n",
        "                low_lim = Q1 - 1.5 * IQR \n",
        "                up_lim = Q3 + 1.5 * IQR \n",
        "                delta = (torch.tensor(up_lim) - torch.tensor(low_lim)) / 2**p\n",
        "            weights[w] = delta * (torch.floor(weights[w]/delta) + 0.5)\n",
        "        for name, params in model.named_parameters():\n",
        "            params.data.copy_(weights[name])\n",
        "\n",
        "        results = results.append(\n",
        "            {'model': model_name, 'method': 'mid-rise', 'precision': p, 'model_artifact': model},\n",
        "            ignore_index=True\n",
        "        )\n",
        "      \n",
        "  return results\n",
        "\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN7hO90Eal-9"
      },
      "source": [
        "Bin Creation Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RukqmLuKM1Yn"
      },
      "source": [
        "\"\"\"\n",
        "Given all weights for a model, the precision and approach, \n",
        "the function calculates a tensor of unique values per layer (weight+bias)\n",
        "Returns unique values for the entire model.\n",
        "\"\"\"\n",
        "\n",
        "def unique_value_generator(weights, precision, approach):\n",
        "  #Parse layers names \n",
        "  network_name=list(set([x.rsplit('.',1)[0] for x in list(weights.keys())]))\n",
        "\n",
        "  unique_values=dict()\n",
        "  for i in network_name:\n",
        "    weight_bias_comb=torch.cat((torch.flatten(weights[i+'.weight']),weights[i+'.bias']),dim=0) #Flattening the weights tensor and concatenating it with bias\n",
        "    print('No. of params in', i, ':', len(set(weight_bias_comb)))\n",
        "    #Number of unique weights should be more than the number of bins\n",
        "    if len(set(weight_bias_comb)) > 2**precision: \n",
        "      \n",
        "      #uniform range based on min and max\n",
        "      if approach =='uniform_range':\n",
        "        min_val=torch.min(weight_bias_comb).item()\n",
        "        max_val=torch.max(weight_bias_comb).item()\n",
        "        unique_values[i+'.weight']=torch.linspace(start = min_val, end = max_val, steps = 2**precision) \n",
        "        unique_values[i+'.bias']=torch.linspace(start = min_val, end = max_val, steps = 2**precision)\n",
        "\n",
        "      #uniform range post outlier removal\n",
        "      if approach == 'uniform_range_IQR':\n",
        "        weight_bias_comb=np.sort(weight_bias_comb.detach().numpy())\n",
        "        Q1 = np.percentile(weight_bias_comb, 25, interpolation = 'midpoint')  \n",
        "        Q2 = np.percentile(weight_bias_comb, 50, interpolation = 'midpoint')  \n",
        "        Q3 = np.percentile(weight_bias_comb, 75, interpolation = 'midpoint')  \n",
        "        IQR=Q3-Q1\n",
        "        low_lim = Q1 - 1.5 * IQR \n",
        "        up_lim = Q3 + 1.5 * IQR \n",
        "        unique_values[i+'.weight']=torch.linspace(start = low_lim, end = up_lim, steps = 2**precision)\n",
        "        unique_values[i+'.bias']=torch.linspace(start = low_lim, end = up_lim, steps = 2**precision) \n",
        "\n",
        "      #Range based on quantiles of a normal distribution\n",
        "      if approach == 'prior_normal':\n",
        "        mean_val=torch.mean(weight_bias_comb).item()\n",
        "        std_val=torch.std(weight_bias_comb).item()\n",
        "        quantiles=np.linspace(0, 1, num=2**precision) #Quantile \n",
        "        quantiles=quantiles[:-1][1:] #Removing 1st and last element \n",
        "        unique_intm = list(map(lambda x : norm.ppf(x,loc=mean_val,scale=std_val), quantiles)) \n",
        "        unique_intm.append(torch.min(weight_bias_comb).item())\n",
        "        unique_intm.append(torch.max(weight_bias_comb).item())\n",
        "        unique_intm=torch.tensor(np.array(unique_intm))\n",
        "        unique_values[i+'.weight']=unique_intm\n",
        "        unique_values[i+'.bias']=unique_intm\n",
        "\n",
        "    #If number of unique weights is less than or equal to the number of bins being created, no need to create bins\n",
        "    else: \n",
        "      print('Bins not created for', i)\n",
        "      unique_values[i+'.weight']=weights[i+'.weight']\n",
        "      unique_values[i+'.bias']=weights[i+'.bias']\n",
        "      \n",
        "  return unique_values"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK4Tcv4aaq6i"
      },
      "source": [
        "**Quantization Techniques**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIhm__CsaVXO"
      },
      "source": [
        "'''\n",
        "Given a \"weights\" tensor and a \"tensor of unique values\", \n",
        "This function will quantize all scalar values of \"weights\" \n",
        "to one of unique values using stochastic quantization.\n",
        "Input: \n",
        "  weights = torch.tensor([[1.2,3.4], [2.6, 8.9]])\n",
        "  unique_values = torch.tensor([0.5, 1.5])\n",
        "'''\n",
        "def stochastic_quant(weights, unique_values): \n",
        "  # inner helper function \n",
        "  def stochastic_helper(w):\n",
        "    i = 0\n",
        "    n = len(unique_values)\n",
        "    while(i<n and unique_values[i]<w):\n",
        "      i+=1\n",
        "\n",
        "    # base case\n",
        "    if i==0: return unique_values[0]\n",
        "    elif i==n: return unique_values[n-1]\n",
        "\n",
        "    # general case\n",
        "    lower, upper = unique_values[i-1], unique_values[i]\n",
        "    lower_p = (upper - w)/(upper - lower)\n",
        "    lower_pick = np.random.binomial(n=1, p=lower_p.item())\n",
        "\n",
        "    return lower_pick*lower + (1-lower_pick)*upper\n",
        "\n",
        "  # soring unique values\n",
        "  unique_values = torch.sort(unique_values.flatten()).values.cpu()\n",
        "  # apply_ only works on cpu tensor, so making a copy on cpu\n",
        "  weights1 = weights.clone().detach().cpu()\n",
        "  # apply stochastic quantization to all values in weights\n",
        "  weights1.apply_(stochastic_helper)\n",
        "  weights1 = weights1.to(weights.device)\n",
        "\n",
        "  return weights1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmwSqWCyaZgz"
      },
      "source": [
        "'''\n",
        "Given a \"weights\" tensor and a \"tensor of unique values\", \n",
        "This function will quantize all scalar values of \"weights\" \n",
        "to the nearest unique value.\n",
        "Input: \n",
        "  weights = torch.tensor([[1.2,3.4], [2.6, 8.9]])\n",
        "  unique_values = torch.tensor([0.5, 1.5])\n",
        "'''\n",
        "def rounding_quant(weights, unique_values): \n",
        "  # inner helper function \n",
        "  def rounding_helper(w):\n",
        "    i = 0\n",
        "    n = len(unique_values)\n",
        "    while(i<n and unique_values[i]<w):\n",
        "      i+=1\n",
        "\n",
        "    # base case\n",
        "    if i==0: return unique_values[0]\n",
        "    elif i==n: return unique_values[n-1]\n",
        "\n",
        "    # general case\n",
        "    lower, upper = unique_values[i-1], unique_values[i]\n",
        "    if (w - lower) < (upper - w):\n",
        "      return lower\n",
        "    return upper\n",
        "\n",
        "  # soring unique values\n",
        "  unique_values = torch.sort(unique_values.flatten()).values.cpu()\n",
        "  # apply_ only works on cpu tensor, so making a copy on cpu\n",
        "  weights1 = weights.clone().detach().cpu()\n",
        "  # apply rounding quantization to all values in weights\n",
        "  weights1.apply_(rounding_helper)\n",
        "  weights1 = weights1.to(weights.device)\n",
        "\n",
        "  return weights1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke7Igrrxau1n"
      },
      "source": [
        "**Testing Binning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGEwnoGQWfQZ",
        "outputId": "ec732368-8900-4ff9-8c1a-b89077dd1051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model_name='telescope_simple.pt'\n",
        "precision=4\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_object = 'model_artifacts/' + model_name\n",
        "results = pd.DataFrame(columns=['model', 'method', 'precision', 'model_artifact',\n",
        "                            'train_loss', 'train_acc', 'test_loss', 'test_acc'])\n",
        "\n",
        "model = torch.load(model_object, map_location=torch.device(device))\n",
        "weights=dict()\n",
        "for name, params in model.named_parameters():\n",
        "  weights[name] = params.clone()\n",
        "\n",
        "check=unique_value_generator(weights, precision, 'prior_normal')"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of params in net.0 : 110\n",
            "No. of params in net.2 : 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmeoriu6XHVE",
        "outputId": "db9994b4-2bfd-4787-d166-0dd873e4749c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model_name='telescope_complex.pt'\n",
        "precision=8\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_object = 'model_artifacts/' + model_name\n",
        "results = pd.DataFrame(columns=['model', 'method', 'precision', 'model_artifact',\n",
        "                            'train_loss', 'train_acc', 'test_loss', 'test_acc'])\n",
        "\n",
        "model = torch.load(model_object, map_location=torch.device(device))\n",
        "weights=dict()\n",
        "for name, params in model.named_parameters():\n",
        "  weights[name] = params.clone()\n",
        "\n",
        "check=unique_value_generator(weights, precision, 'prior_normal')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of params in net.9 : 1830\n",
            "No. of params in net.0 : 220\n",
            "Bins not created for net.0\n",
            "No. of params in net.3 : 840\n",
            "No. of params in net.12 : 62\n",
            "Bins not created for net.12\n",
            "No. of params in net.6 : 2460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGn8uv6zXM5T",
        "outputId": "591fa7b0-0a7e-4fc1-89ed-c6f8afe6fe08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model_name='cifar_cnn_model.pt'\n",
        "precision=12\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_object = 'model_artifacts/' + model_name\n",
        "results = pd.DataFrame(columns=['model', 'method', 'precision', 'model_artifact',\n",
        "                            'train_loss', 'train_acc', 'test_loss', 'test_acc'])\n",
        "\n",
        "model = torch.load(model_object, map_location=torch.device(device))\n",
        "weights=dict()\n",
        "for name, params in model.named_parameters():\n",
        "  weights[name] = params.clone()\n",
        "\n",
        "check=unique_value_generator(weights, precision, 'prior_normal')"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of params in network.12 : 256\n",
            "Bins not created for network.12\n",
            "No. of params in network.11 : 147584\n",
            "No. of params in network.26 : 51300\n",
            "No. of params in network.0 : 896\n",
            "Bins not created for network.0\n",
            "No. of params in network.8 : 256\n",
            "Bins not created for network.8\n",
            "No. of params in network.7 : 73856\n",
            "No. of params in network.16 : 512\n",
            "Bins not created for network.16\n",
            "No. of params in network.24 : 2097664\n",
            "No. of params in network.19 : 512\n",
            "Bins not created for network.19\n",
            "No. of params in network.18 : 590080\n",
            "No. of params in network.15 : 295168\n",
            "No. of params in network.1 : 64\n",
            "Bins not created for network.1\n",
            "No. of params in network.3 : 18496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EiOK0Q7NCzo"
      },
      "source": [
        ""
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCcv9pH1Mswc"
      },
      "source": [
        ""
      ],
      "execution_count": 92,
      "outputs": []
    }
  ]
}