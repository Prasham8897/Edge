{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_cifar.ipynb","provenance":[],"collapsed_sections":["c3rr31yXB4P2","yes0ALHOiMrb","9D1FU_OG79H8"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"07c5fd5728b2445bbc16615da1a9c5f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_67e5196d2b4b484996403c64b2e1601d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_74d66c01bd2443bd97e03100205a0cf0","IPY_MODEL_9656fd1df08d4bdda9d90d18916c2e82"]}},"67e5196d2b4b484996403c64b2e1601d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"74d66c01bd2443bd97e03100205a0cf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f4a3887450c442faa124167b7680816c","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7191d54f38b44fe99fb69ce979609ef"}},"9656fd1df08d4bdda9d90d18916c2e82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0798cb5429e64292a202f796d8115b31","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:05&lt;00:00, 121.81it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce0c34b0dbf9438abe0c9e06bad03f70"}},"f4a3887450c442faa124167b7680816c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a7191d54f38b44fe99fb69ce979609ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0798cb5429e64292a202f796d8115b31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ce0c34b0dbf9438abe0c9e06bad03f70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9343e58101a1449fb3327548653e591a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_496cd29bfa3d4bb0aa517ec780010312","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9caae812bc914526a999a1a9d3429b2a","IPY_MODEL_5a023dddee774d07adeaae32143195bb"]}},"496cd29bfa3d4bb0aa517ec780010312":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"9caae812bc914526a999a1a9d3429b2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_569c994774d342b89d73168033a9e5ac","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f0b97c22fc364fdd8355528e8be1be7a"}},"5a023dddee774d07adeaae32143195bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aec2ee1b91154557aed5d428d688058c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [00:25&lt;00:00, 122.69it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68fc62aff3794645a5141032d9baaf6b"}},"569c994774d342b89d73168033a9e5ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f0b97c22fc364fdd8355528e8be1be7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aec2ee1b91154557aed5d428d688058c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"68fc62aff3794645a5141032d9baaf6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54faf59af68a4e918d1a996cbf155428":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_774718c252274f1381e65c9f1dccbbf4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8b7a19f95bf540efb4dadbe048376d0a","IPY_MODEL_73d078d2fd7c48fc8b5ae8aca8f00043"]}},"774718c252274f1381e65c9f1dccbbf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"8b7a19f95bf540efb4dadbe048376d0a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d52b871f260f417cb64e7ab425fe048f","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97b0953d5e694591ac4da21ebd7075b1"}},"73d078d2fd7c48fc8b5ae8aca8f00043":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41fc12c8c34c4aeeb59bc81bf08b9a95","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [05:34&lt;00:00,  1.87it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2777d4818fe543abab4411a9014e1463"}},"d52b871f260f417cb64e7ab425fe048f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"97b0953d5e694591ac4da21ebd7075b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41fc12c8c34c4aeeb59bc81bf08b9a95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2777d4818fe543abab4411a9014e1463":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfe6cb2e322c4ce69a53378eaafb4130":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2269b87f68404f1a85a590664fc3fc11","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f25b5db84a3546e4865c239be2aec5e5","IPY_MODEL_86e9401df1434ffe8e50e5da5d6b1342"]}},"2269b87f68404f1a85a590664fc3fc11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"f25b5db84a3546e4865c239be2aec5e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_79fb54b7e2ad4f888bda9818d46e7c9d","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bca9b44157464330bce3dfdde9f6a13e"}},"86e9401df1434ffe8e50e5da5d6b1342":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0542d2a2fde945b299780227d1be5220","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [00:30&lt;00:00, 102.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d488e6ca12040649534b15b2662ba1c"}},"79fb54b7e2ad4f888bda9818d46e7c9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bca9b44157464330bce3dfdde9f6a13e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0542d2a2fde945b299780227d1be5220":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d488e6ca12040649534b15b2662ba1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11a37d606e564ff08fd38cdd3660f615":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c4c5d4869b6e4c2ea920e7c6d7ecc208","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6c63d2fe7b694506bd1f17e7116a539f","IPY_MODEL_c520b639e106472692959429b7e7324f"]}},"c4c5d4869b6e4c2ea920e7c6d7ecc208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"6c63d2fe7b694506bd1f17e7116a539f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34ddeabf88ad4b849b0993b2a86d89a9","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7b2b94a2b354690a9a6ca77cab69bfb"}},"c520b639e106472692959429b7e7324f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_297cf8a7276d4845915a6904ec9c3142","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:05&lt;00:00, 115.27it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4e27bb3d5d0416ba9895278c0c72d0f"}},"34ddeabf88ad4b849b0993b2a86d89a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e7b2b94a2b354690a9a6ca77cab69bfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"297cf8a7276d4845915a6904ec9c3142":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d4e27bb3d5d0416ba9895278c0c72d0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4f533576e4345898b1cc2dbcf5da193":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_afa0e4b98d124ad08fccd179a46aa6d1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b687b48d52814d7ba691d5c793ed662e","IPY_MODEL_de06568d02744c178bf541bdb5a77daa"]}},"afa0e4b98d124ad08fccd179a46aa6d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"b687b48d52814d7ba691d5c793ed662e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9e43344d5e7146d9af395e8fe3d3d429","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5cf81b50134448f09ad901cef4440afd"}},"de06568d02744c178bf541bdb5a77daa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ae987a64c3ce4140b9a277e323ab3f50","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:05&lt;00:00, 117.16it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86fa430f355b4c05a427c2f58d34c42c"}},"9e43344d5e7146d9af395e8fe3d3d429":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5cf81b50134448f09ad901cef4440afd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae987a64c3ce4140b9a277e323ab3f50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"86fa430f355b4c05a427c2f58d34c42c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1af47ea8e5c4a8bae4f84c1c856576a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e115d59e25dc4189a0842ef31a899284","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_54525c22524b4bf7bc4824f973d58e9d","IPY_MODEL_3360cfbb41004e35977f3ef1714fb283"]}},"e115d59e25dc4189a0842ef31a899284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"54525c22524b4bf7bc4824f973d58e9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4e9fa7e4af7d458781d1d9fe1e4c53cf","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_456c1a3340ff4052a334ca91fc5c3be9"}},"3360cfbb41004e35977f3ef1714fb283":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2f6b1ba6b64841d6bc969f6f787a70f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [00:30&lt;00:00, 102.42it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9303a5b25bac4b869663939d3c6a4bd0"}},"4e9fa7e4af7d458781d1d9fe1e4c53cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"456c1a3340ff4052a334ca91fc5c3be9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f6b1ba6b64841d6bc969f6f787a70f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9303a5b25bac4b869663939d3c6a4bd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a351256d3e4456b9bb220459a83f24b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c1ce012599814315ba1c676115c0cec6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_47f5a6daa2984408b2c52bd74903d627","IPY_MODEL_e89edb89cb5a44c78547c4c7ba2bb139"]}},"c1ce012599814315ba1c676115c0cec6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"47f5a6daa2984408b2c52bd74903d627":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a44b442f9e504152b059278a7dd78a69","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9485fac4581646d09f698b25ad953e09"}},"e89edb89cb5a44c78547c4c7ba2bb139":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fb719cc17a5f405f8d43e39151409570","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:05&lt;00:00, 113.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0267e5751788430cab9ad9737c0139ed"}},"a44b442f9e504152b059278a7dd78a69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9485fac4581646d09f698b25ad953e09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb719cc17a5f405f8d43e39151409570":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0267e5751788430cab9ad9737c0139ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"417fcf763fa744ccbfa5f4858ab9b6ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fef201efddca4f45ba5fa35d7e2e0a52","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cf58a3e7a3dd49cba0f932fca2e521ee","IPY_MODEL_2b17414b8c6848658dddd103092a9b3b"]}},"fef201efddca4f45ba5fa35d7e2e0a52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"cf58a3e7a3dd49cba0f932fca2e521ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fe694402f17f4e76b3e6689a2f57118d","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75710795934049fab80e41f171c5e214"}},"2b17414b8c6848658dddd103092a9b3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ffa908166bb04bb8968e64c8ffc21b76","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [03:12&lt;00:00, 16.20it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_881c09ba38684e03b1f8988d5419395c"}},"fe694402f17f4e76b3e6689a2f57118d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75710795934049fab80e41f171c5e214":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ffa908166bb04bb8968e64c8ffc21b76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"881c09ba38684e03b1f8988d5419395c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c0020db454d427a95bc8ed9c5bd4b44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7504ac6f682f443487ea1c102fb501aa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8289c948cc0540e2bd4c99fa98f6048c","IPY_MODEL_53fb7eb41a254404bb084e43a82df985"]}},"7504ac6f682f443487ea1c102fb501aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"8289c948cc0540e2bd4c99fa98f6048c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b9016f06530f46af90273c21ed340972","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b79d835fdcd04fe3b43b57ed2130a946"}},"53fb7eb41a254404bb084e43a82df985":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_20545ae8e0c24042bd6e74a7cba8d9b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [02:00&lt;00:00,  5.20it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_491af09bd1e5449fa030d53d91b69e47"}},"b9016f06530f46af90273c21ed340972":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b79d835fdcd04fe3b43b57ed2130a946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20545ae8e0c24042bd6e74a7cba8d9b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"491af09bd1e5449fa030d53d91b69e47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4e36c69798f4fd1adb5f8dca5d26b4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a3801bc126a4418981117c075f399459","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ccc3a42cc0f24eaa9a2d9aa0ae5b96c1","IPY_MODEL_791c97d79dfc42769815c195346e3940"]}},"a3801bc126a4418981117c075f399459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"ccc3a42cc0f24eaa9a2d9aa0ae5b96c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3a55e569e3554b658824458be0c0f11b","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_244384b017f94c36994e5739d95f38d9"}},"791c97d79dfc42769815c195346e3940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1c98cb114af54f60855b80271025c15a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:19&lt;00:00, 31.40it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f02a4f6978774de4990e7a07580a9a41"}},"3a55e569e3554b658824458be0c0f11b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"244384b017f94c36994e5739d95f38d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c98cb114af54f60855b80271025c15a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f02a4f6978774de4990e7a07580a9a41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44d86609934c44ed99467a35d1b84cad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_430f7077235c4ac3a996e616f1e9b7a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ad10ff76531f4877b5ab3003dc664f3e","IPY_MODEL_374e8dec900d493296accdc6b001d9f8"]}},"430f7077235c4ac3a996e616f1e9b7a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"ad10ff76531f4877b5ab3003dc664f3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2336c4c03824435f869fe39b57dbe898","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53a161df98134cec89c72014d357e88f"}},"374e8dec900d493296accdc6b001d9f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_144b5ba611ec413183b6796c9aa49ad5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [01:59&lt;00:00, 26.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_649bcdf40ca84fc785cd38534c814258"}},"2336c4c03824435f869fe39b57dbe898":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"53a161df98134cec89c72014d357e88f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"144b5ba611ec413183b6796c9aa49ad5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"649bcdf40ca84fc785cd38534c814258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98f568eca51e4742ab208122e20be751":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_196b58571f3b4b839a731444904648e8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_72aa6365dceb427fa7d11f7f75355ff3","IPY_MODEL_316a88c4c838468399a0c59467deb500"]}},"196b58571f3b4b839a731444904648e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"72aa6365dceb427fa7d11f7f75355ff3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4bd9cf0a84674814a52baf55cba4204c","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1361585476434ddb9af31cace8a1f4bd"}},"316a88c4c838468399a0c59467deb500":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8c27721dd8a242e3868fcd25e699b286","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:20&lt;00:00, 30.97it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f862de0da7f64033ba6a1871ca74502b"}},"4bd9cf0a84674814a52baf55cba4204c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1361585476434ddb9af31cace8a1f4bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c27721dd8a242e3868fcd25e699b286":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f862de0da7f64033ba6a1871ca74502b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"432a0766346443868154bddd7a3351ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6c96dfa2dd4645b3862e319b76f8fd7b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2789700d8a804061a4e9862f49ee4522","IPY_MODEL_4e3c8cdba5a34770ac3005164e5e7b1d"]}},"6c96dfa2dd4645b3862e319b76f8fd7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"2789700d8a804061a4e9862f49ee4522":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_28f0e58f55634d7fa32f4ca2b9b2f4d8","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_70ec434313364a4fafd40364c5f53415"}},"4e3c8cdba5a34770ac3005164e5e7b1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1156eabf9a0346b3b44e34be420cbc99","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [09:26&lt;00:00,  5.51it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95f99527ff834aa6acfd8a752418b050"}},"28f0e58f55634d7fa32f4ca2b9b2f4d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"70ec434313364a4fafd40364c5f53415":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1156eabf9a0346b3b44e34be420cbc99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"95f99527ff834aa6acfd8a752418b050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fbed456b67f54a8c960d6d9f0ded9e5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_82038eebc5ed4edb97fe87e88fac2e2e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c3769fe8e9db41e683d56b687e05568b","IPY_MODEL_94d44edf6bfb42afb34cb1586e3e07d8"]}},"82038eebc5ed4edb97fe87e88fac2e2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"c3769fe8e9db41e683d56b687e05568b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9d9f8869dd364111a35aee8972532a98","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4610c693509c468c9d269119aae4c4ee"}},"94d44edf6bfb42afb34cb1586e3e07d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41ca6c52c38b4ae79fe7a07b27344912","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [02:00&lt;00:00,  5.20it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5ac8bb7eecd64ddd894cf030f6c4a409"}},"9d9f8869dd364111a35aee8972532a98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4610c693509c468c9d269119aae4c4ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41ca6c52c38b4ae79fe7a07b27344912":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5ac8bb7eecd64ddd894cf030f6c4a409":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88d762f810684c008b6e04292a88e11f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c08c20d4b374065a4bd92e013cab9fc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_702b15a9c96e4506adb5bd1c06c79192","IPY_MODEL_5654af108c394a06b83fc46ad3e608f3"]}},"2c08c20d4b374065a4bd92e013cab9fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"702b15a9c96e4506adb5bd1c06c79192":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f5fee20332544a3c82f04110989aef74","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_98b759f47d894290bd75f685661fdc5a"}},"5654af108c394a06b83fc46ad3e608f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_22460ffadd6443ae9d11a55c32b5fc45","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [01:40&lt;00:00, 31.23it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1986bb03aa3943dd9e16ce30336c5f13"}},"f5fee20332544a3c82f04110989aef74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"98b759f47d894290bd75f685661fdc5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22460ffadd6443ae9d11a55c32b5fc45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1986bb03aa3943dd9e16ce30336c5f13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b944d0c1aaa84e1c9954522f80eb3717":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ec1033f7886a4be1ba18ef7b688ab866","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b6826111b044951bf6bb3f2d232beaa","IPY_MODEL_a5f7b0acc3c247e0b2874eacff7405b0"]}},"ec1033f7886a4be1ba18ef7b688ab866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"6b6826111b044951bf6bb3f2d232beaa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_66988e13240c4b499027bcfa01bff41f","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b5062a5b158f4842bea47a2db9c00504"}},"a5f7b0acc3c247e0b2874eacff7405b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_879ea73d093a4bda8ed4cc472aed7e48","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [05:47&lt;00:00,  1.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e2124a996e81419898012034a9fcfc94"}},"66988e13240c4b499027bcfa01bff41f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b5062a5b158f4842bea47a2db9c00504":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"879ea73d093a4bda8ed4cc472aed7e48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e2124a996e81419898012034a9fcfc94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2bbae422112a4f068c6e711ee8c2d694":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf3529bcc08d4f1d8432ef6fd5898fa3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4670212ce6e24c389237b8cf10833e06","IPY_MODEL_6fb9d2cd2d6044478958c7e5761d533a"]}},"bf3529bcc08d4f1d8432ef6fd5898fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"4670212ce6e24c389237b8cf10833e06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_48107a86e5a04d3db304306d965bbb00","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51684a9bbb9849f1a7c4a00bb516aaae"}},"6fb9d2cd2d6044478958c7e5761d533a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_229d0ad4baae443bb3f53bc08b30864b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [01:58&lt;00:00, 26.41it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7dd9822fbb8047f1bea595267863caf0"}},"48107a86e5a04d3db304306d965bbb00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"51684a9bbb9849f1a7c4a00bb516aaae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"229d0ad4baae443bb3f53bc08b30864b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7dd9822fbb8047f1bea595267863caf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d6509e3ba55a4a0683414c65c45c7914":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e2543b3202143c6b13014f181a2b0a2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f199fb10447b4b0293b90abbfac09744","IPY_MODEL_1590d64c86c34acebe7407df8a1c813f"]}},"4e2543b3202143c6b13014f181a2b0a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"f199fb10447b4b0293b90abbfac09744":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5e67010baa974d2484758d37a0c5bcfd","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b66796895fc04194ae529c4dd0361fc5"}},"1590d64c86c34acebe7407df8a1c813f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d5f12fd843648bb92c26f82f2160095","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:20&lt;00:00, 30.85it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e87ae72498334839bf4e4a45aed366ad"}},"5e67010baa974d2484758d37a0c5bcfd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b66796895fc04194ae529c4dd0361fc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d5f12fd843648bb92c26f82f2160095":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e87ae72498334839bf4e4a45aed366ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43ff4da758b742679d68c52c5701004e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b7a3680fe6c64686a40fcc8faeae4ee6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2a4e3fe41cd349d38443c6e2e36e3a22","IPY_MODEL_8860321f61cb4c66bb943d1e8d82155e"]}},"b7a3680fe6c64686a40fcc8faeae4ee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"2a4e3fe41cd349d38443c6e2e36e3a22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_830bdbef77d84521bb138bacc5138ddf","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b972eba934e740c9b5991f00354e00cc"}},"8860321f61cb4c66bb943d1e8d82155e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4556a7a390034077b970b1c9679f15be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3125/3125 [03:29&lt;00:00, 14.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_19d185c94ec94583abeeeda340efd5dd"}},"830bdbef77d84521bb138bacc5138ddf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b972eba934e740c9b5991f00354e00cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4556a7a390034077b970b1c9679f15be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"19d185c94ec94583abeeeda340efd5dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c85ee8b3eb348d396ab6c81e5388cc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5eff4b5a0f0041b09f6bb7359a160842","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e18673429c7c479284db2e5fed3ac7a6","IPY_MODEL_6d1b0997597f44f18a379b5595c447c5"]}},"5eff4b5a0f0041b09f6bb7359a160842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"e18673429c7c479284db2e5fed3ac7a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2010f00d28404b2abc7d07b450370485","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c5705b9e787a4cc0a787448012d00e6d"}},"6d1b0997597f44f18a379b5595c447c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_24532cbffac040ae96328a927fb7936e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [01:33&lt;00:00,  6.70it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f52e370157bf4b83866c328ccff69fc6"}},"2010f00d28404b2abc7d07b450370485":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c5705b9e787a4cc0a787448012d00e6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"24532cbffac040ae96328a927fb7936e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f52e370157bf4b83866c328ccff69fc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5279ad6a4f14f8b84fdc378e4cce724":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_632635c4ef50451c9a846d44dab8155f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3415351a2f704a4e9c74b022efb0aec0","IPY_MODEL_0a9c31190f02410896a611cad28a2421"]}},"632635c4ef50451c9a846d44dab8155f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"3415351a2f704a4e9c74b022efb0aec0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f4c5c52994c9420ca079a4c757885a4d","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":313,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":313,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1d934c7bb4849e2a5fc89a4ccedb292"}},"0a9c31190f02410896a611cad28a2421":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57f2bb9c9a3e45bb9ea16fc565aedae7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 313/313 [00:28&lt;00:00, 10.95it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ad998429b9f4a428608014a7c858d61"}},"f4c5c52994c9420ca079a4c757885a4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b1d934c7bb4849e2a5fc89a4ccedb292":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57f2bb9c9a3e45bb9ea16fc565aedae7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1ad998429b9f4a428608014a7c858d61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dbe371b07b954861847ee82f4a9c9bd5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cb0db3dee137408f89f5fbdf2aa881ff","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ff9460b09bdd48929c372028e0a0604b","IPY_MODEL_96a190535f644e63a679eb1649779c14"]}},"cb0db3dee137408f89f5fbdf2aa881ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"ff9460b09bdd48929c372028e0a0604b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ea8d8a772eb64dc5b103fde0d356245d","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1563,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1563,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a01bea565ecc4aa8a0301dabec296ecf"}},"96a190535f644e63a679eb1649779c14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_913d8553ee0642b38bb0e48ae2a42f32","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1563/1563 [02:50&lt;00:00,  9.19it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac188bef39a444298fc89ee77272bd60"}},"ea8d8a772eb64dc5b103fde0d356245d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a01bea565ecc4aa8a0301dabec296ecf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"913d8553ee0642b38bb0e48ae2a42f32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ac188bef39a444298fc89ee77272bd60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74806d17d4b04e11881c0b783af45ede":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6bd8024bdc5a452a8babf066bca1b0d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0509c0ce140b494da8dfd494fd2b608c","IPY_MODEL_f47a6675e4b94fccb6d9b3eb20ea0599"]}},"6bd8024bdc5a452a8babf066bca1b0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"0509c0ce140b494da8dfd494fd2b608c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_89e75f1b8d49405492d7a4f0210d7fe1","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":313,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":313,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1860cfe71eef467081d63ac084979024"}},"f47a6675e4b94fccb6d9b3eb20ea0599":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c87344bfaea74ca7befca4da819208e1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 313/313 [00:28&lt;00:00, 10.81it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b745fa956fbb48d987737cdb12896c17"}},"89e75f1b8d49405492d7a4f0210d7fe1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1860cfe71eef467081d63ac084979024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c87344bfaea74ca7befca4da819208e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b745fa956fbb48d987737cdb12896c17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9dbcaed59e348d88105628af83231ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7bed0049f6764eea8d593c63b45ee434","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e86008d281e04f93ae1f03cb9edc7c8b","IPY_MODEL_62cfaf10cbb84c71b4c91583354bf599"]}},"7bed0049f6764eea8d593c63b45ee434":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"e86008d281e04f93ae1f03cb9edc7c8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b204169035874379aee1e4a474bb7d56","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1563,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1563,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af83bae4f0194b1093b50266ce794448"}},"62cfaf10cbb84c71b4c91583354bf599":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b164a8b97ba74a50af908331530909cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1563/1563 [02:21&lt;00:00, 11.06it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ccd174d21d049d48af0f2436d9aed9c"}},"b204169035874379aee1e4a474bb7d56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"af83bae4f0194b1093b50266ce794448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b164a8b97ba74a50af908331530909cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0ccd174d21d049d48af0f2436d9aed9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4176c0a0e564434a728ceb23bc48643":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a62a5504815b4524a0d2a5a2b9fcf8ce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_43a6f106f9a145b7851ca14ccb78b74e","IPY_MODEL_aef7a8ff0539499190179d9c1789ff62"]}},"a62a5504815b4524a0d2a5a2b9fcf8ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"900px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"43a6f106f9a145b7851ca14ccb78b74e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dd5e5cc586a441d0bcf33242e0534220","_dom_classes":[],"description":"Eval Iteration for epoch:1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":313,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":313,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_566c51e6ca5d49b7913ab01efef067a5"}},"aef7a8ff0539499190179d9c1789ff62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b56169d000448f6a552c360946945e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 313/313 [00:28&lt;00:00, 10.97it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d1aa42b7e9643feae31f86a3e6a75cb"}},"dd5e5cc586a441d0bcf33242e0534220":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"566c51e6ca5d49b7913ab01efef067a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b56169d000448f6a552c360946945e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d1aa42b7e9643feae31f86a3e6a75cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"0kYfYIYfA5X1"},"source":["## Drive mount/ Common"]},{"cell_type":"code","metadata":{"id":"YqpvV7WFA862","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605857747354,"user_tz":480,"elapsed":22116,"user":{"displayName":"Kumari Nishu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFdfS8IitH2P71X64Sf8cglHIG79P672a7SbQD=s64","userId":"13793804378645653224"}},"outputId":"bb4a6f38-87b8-422a-b68a-57bd2cc96ee5"},"source":["from google.colab import drive # import drive from google colab\n","ROOT = \"/content/drive\"     # default location for the drive\n","PROJECT_PATH = ROOT+'/My Drive/Fall2020/My_Capstone/'\n","drive.mount(ROOT, force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JrxJuOP8BTw_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605857750696,"user_tz":480,"elapsed":407,"user":{"displayName":"Kumari Nishu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFdfS8IitH2P71X64Sf8cglHIG79P672a7SbQD=s64","userId":"13793804378645653224"}},"outputId":"982ccba9-cd72-4b17-d537-86690782be3a"},"source":["%cd \"{PROJECT_PATH}\"\n","#!git clone -b Pritam \"{GIT_PATH}\"\n","%cd \"Edge\"\n","# %%writefile train_california.py\n","# import importlib\n","# from utils.post_training_quantization import multipoint_quantization as mt\n","# importlib.reload(mt)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Fall2020/My_Capstone\n","/content/drive/My Drive/Fall2020/My_Capstone/Edge\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oydlXr76kZuo"},"source":["import importlib\n","from utils.post_training_quantization import multipoint_quantization as mt\n","importlib.reload(mt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2GttDRhv7wcy"},"source":["# using models written in results csv, find accuracy on train and test data\n","def quantization_eval_results(results,train_set,test_set,batch_size,criterion):\n","  train_loss_list = []\n","  train_accuracy_list = []\n","  test_loss_list = []\n","  test_accuracy_list = []\n","  for i in results[\"model_artifact\"]:\n","    train_loss, train_accuracy = evaluate(model=i, \n","                                        test_set = train_set,\n","                                        batch_size=batch_size, \n","                                        criterion=criterion,\n","                                        ep=0) \n","    test_loss, test_accuracy = evaluate(model=i, \n","                                        test_set = test_set,\n","                                        batch_size=batch_size, \n","                                        criterion=criterion,\n","                                        ep=0)  \n","    train_loss_list.append(train_loss.item())\n","    test_loss_list.append(test_loss.item())\n","    train_accuracy_list.append(train_accuracy)\n","    test_accuracy_list.append(test_accuracy)\n","  # append rest of results\n","  results[\"train_loss\"] = train_loss_list\n","  results[\"train_acc\"] = train_accuracy_list\n","  results[\"test_loss\"] = test_loss_list\n","  results[\"test_acc\"] = test_accuracy_list\n","  return results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c3rr31yXB4P2"},"source":["# **Model = ConvNet, Data = CIFAR100 data**\n","Val Accuracy=46%"]},{"cell_type":"code","metadata":{"id":"bgNpW9e54hAE","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["07c5fd5728b2445bbc16615da1a9c5f3","67e5196d2b4b484996403c64b2e1601d","74d66c01bd2443bd97e03100205a0cf0","9656fd1df08d4bdda9d90d18916c2e82","f4a3887450c442faa124167b7680816c","a7191d54f38b44fe99fb69ce979609ef","0798cb5429e64292a202f796d8115b31","ce0c34b0dbf9438abe0c9e06bad03f70","9343e58101a1449fb3327548653e591a","496cd29bfa3d4bb0aa517ec780010312","9caae812bc914526a999a1a9d3429b2a","5a023dddee774d07adeaae32143195bb","569c994774d342b89d73168033a9e5ac","f0b97c22fc364fdd8355528e8be1be7a","aec2ee1b91154557aed5d428d688058c","68fc62aff3794645a5141032d9baaf6b","54faf59af68a4e918d1a996cbf155428","774718c252274f1381e65c9f1dccbbf4","8b7a19f95bf540efb4dadbe048376d0a","73d078d2fd7c48fc8b5ae8aca8f00043","d52b871f260f417cb64e7ab425fe048f","97b0953d5e694591ac4da21ebd7075b1","41fc12c8c34c4aeeb59bc81bf08b9a95","2777d4818fe543abab4411a9014e1463","dfe6cb2e322c4ce69a53378eaafb4130","2269b87f68404f1a85a590664fc3fc11","f25b5db84a3546e4865c239be2aec5e5","86e9401df1434ffe8e50e5da5d6b1342","79fb54b7e2ad4f888bda9818d46e7c9d","bca9b44157464330bce3dfdde9f6a13e","0542d2a2fde945b299780227d1be5220","7d488e6ca12040649534b15b2662ba1c","11a37d606e564ff08fd38cdd3660f615","c4c5d4869b6e4c2ea920e7c6d7ecc208","6c63d2fe7b694506bd1f17e7116a539f","c520b639e106472692959429b7e7324f","34ddeabf88ad4b849b0993b2a86d89a9","e7b2b94a2b354690a9a6ca77cab69bfb","297cf8a7276d4845915a6904ec9c3142","d4e27bb3d5d0416ba9895278c0c72d0f"]},"executionInfo":{"status":"ok","timestamp":1605858060066,"user_tz":480,"elapsed":70864,"user":{"displayName":"Kumari Nishu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFdfS8IitH2P71X64Sf8cglHIG79P672a7SbQD=s64","userId":"13793804378645653224"}},"outputId":"70cf4e55-7369-42c3-944d-218759d688a0"},"source":["# %%writefile train_cifar.py\n","import time\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchsummary import summary\n","\n","from model.dnn import DenseNeuralNet\n","from model.cnn import CNN\n","from utils.post_training_quantization import *\n","from data.mv_data import MVDataset\n","from tqdm.auto import trange, tqdm\n","from tqdm import trange\n","from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","\n","\n","def get_cifar100_dataset(train = True):\n","  transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.5071, 0.4865, 0.4409), std=(0.2673, 0.2564, 0.2762)),\n","  ])\n","\n","  transform_test = transforms.Compose([\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=(0.5071, 0.4865, 0.4409), std=(0.2673, 0.2564, 0.2762)),\n","  ])\n","\n","  if train == True:\n","      dataset = datasets.CIFAR100(root = './data', train = train, transform=transform_test, target_transform=None, download=True)\n","  else:\n","      dataset = datasets.CIFAR100(root = './data', train = train, transform=transform_test, target_transform=None, download=True)\n","  \n","  return dataset\n","\n","\n","def get_accuracy(logits, labels):\n","  preds = torch.argmax(logits, axis=1)\n","  matches = preds == labels\n","  return (matches.sum(), len(labels))\n","\n","\n","def evaluate(model, test_set, batch_size, criterion, ep = 0):\n","  test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, shuffle=True, num_workers=1)\n","  test_iterator = tqdm(test_loader, desc = 'Eval Iteration for epoch:'+str(ep+1), ncols = 900)\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  \n","  model.eval()\n","  global_step = 0\n","  total_correct = 0\n","  total_samples = 0\n","  total_loss = 0.0\n","  with torch.no_grad():\n","    for step, inputs in enumerate(test_iterator):\n","      global_step +=1\n","      # if global_step > 500:\n","      #   break\n","      x, y = inputs[0].to(device), inputs[1].long().to(device)\n","\n","      logits = model(x)\n","      loss = criterion(logits, y)\n","      correct, samples = get_accuracy(logits, y)\n","      total_correct +=correct.item()\n","      total_samples +=samples\n","      total_loss +=loss\n","  # print(total_correct, total_samples)\n","  acc = total_correct / total_samples\n","  total_loss = total_loss / global_step\n","  model.train()\n","  \n","  return (total_loss, acc)\n","\n","\n","def train(model, train_set, val_set, test_set , batch_size = 16, learning_rate = 0.03, epochs = 5, eval_steps = 10, skip_train_set = True):\n","  # logging\n","  train_log = open(\"log/cifar_cnn_train.log\", \"a\")\n","  val_log = open(\"log/cifar_cnn_val.log\", \"a\")\n","  test_log = open(\"log/cifar_cnn_test.log\", \"a\")\n","\n","  # GPU/CPU use\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(\"Device: \", device)\n","  model = model.to(device)\n","  print(\"Model Summary:\")\n","  summary(model, next(iter(train_set))[0].shape)\n","  \n","  # define loss & optimizer\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","  # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","\n","  # iterate over epoch\n","  train_loader = torch.utils.data.DataLoader(dataset= train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n","  global_step = 0\n","  for ep in tqdm(range(epochs), desc = ' Epoch Progress:', ncols=900):\n","    train_iterator = tqdm(train_loader, desc = 'Train Iteration for epoch:'+ str(ep+1), ncols=900)    \n","    running_loss = 0\n","\n","    # iterate over batches\n","    for step, inputs in enumerate(train_iterator):\n","      model.train()\n","      global_step +=1\n","      optimizer.zero_grad()\n","      # predict, find loss, get grads, update weight\n","      x, y = inputs[0].to(device), inputs[1].to(device)\n","      logits = model(x)\n","      loss = criterion(logits, y)\n","      loss.backward()\n","      optimizer.step()\n","      running_loss+=loss.item()\n","\n","    # find validation accuracy\n","    val_loss, val_accuracy = evaluate(model, val_set, batch_size, criterion, ep)\n","    val_log.write(\"Epoch = {}, validation loss =  {}, validation accuracy = {} \\n\".format(ep+1, val_loss, val_accuracy))\n","    print(\"Step = %d, validation loss =  %.3f, validation accuracy = %.3f\" %(global_step, val_loss, val_accuracy))\n","    \n","    # find train accuracy if needed\n","    if not skip_train_set:\n","      train_loss , train_accuracy = evaluate(model, train_set, batch_size, criterion, ep)\n","      train_log.write(\"Epoch = {}, training loss =  {}, training accuracy = {} \\n\".format(ep+1, train_loss, train_accuracy))\n","      print(\"Step = %d, training loss =  %.3f, training accuracy = %.3f\" %(global_step, train_loss, train_accuracy))\n","\n","  # find test accuracy with final model\n","  if test_set is not None:  \n","    test_loss, test_accuracy = evaluate(model, test_set, batch_size, criterion, ep)\n","    test_log.write(\"End of training, test loss =  {}, test accuracy = {} \\n\".format(test_loss, test_accuracy))\n","    print(\"End of Training, test loss =  %.3f, test accuracy = %.3f\" %(test_loss, test_accuracy))\n","\n","  # close log files\n","  train_log.close()\n","  val_log.close()\n","  test_log.close()\n","\n","def main(train_model, quantize):\n","  ### config params \n","  output_classes = 100\n","  learning_rate = 0.001\n","  batch_size = 16\n","  epochs = 10\n","  eval_steps = 100\n","  model_dir = 'model_artifacts'\n","  model_name = 'cifar_cnn_model.pt'\n","  criterion = nn.CrossEntropyLoss()\n","  ####\n","\n","  train_set, val_set, test_set = None, None, None\n","  train_set = get_cifar100_dataset(train = True)\n","  val_set = get_cifar100_dataset(train = False)\n","\n","  if train_model:\n","    model = CNN(output_classes)\n","    train(model, train_set, val_set, test_set , batch_size = batch_size, learning_rate = learning_rate, epochs = epochs, eval_steps = eval_steps, skip_train_set = False)\n","    torch.save(model, os.path.join(model_dir, model_name))\n","\n","  else:\n","    model = torch.load(os.path.join(model_dir, model_name))\n","    val_loss, val_accuracy = evaluate(model, val_set, batch_size, criterion)\n","    print(\"Running evaluation on loaded model, validation loss = %f, validation accuracy = %f\"%(val_loss, val_accuracy))\n","\n","  if quantize:\n","    path_result = \"data/results/multipoint/\"\n","    # Choose Quantization method\n","    results = multipoint_quantization.multipoint_quantization(model_name, precision=[8,6,4,2])\n","    # results = quantization(model_name, method='all')\n","\n","    # Evaluate quantized models\n","    model_results = quantization_eval_results(results,train_set,val_set,batch_size,criterion)\n","    model_results.to_csv(path_result + model_name[:-3]+'_multipoint2' +\".csv\")\n","    print(model_results)\n","\n","\n","if __name__ == \"__main__\":\n","  main(train_model=False, quantize=True)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07c5fd5728b2445bbc16615da1a9c5f3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Running evaluation on loaded model, validation loss = 2.022034, validation accuracy = 0.460300\n","\n","--------Quantizing the model cifar_cnn_model.pt with precision 2\n","All layers except bias layers:  ['network.0.weight', 'network.1.weight', 'network.3.weight', 'network.7.weight', 'network.8.weight', 'network.11.weight', 'network.12.weight', 'network.15.weight', 'network.16.weight', 'network.18.weight', 'network.19.weight', 'network.24.weight', 'network.26.weight']\n","\n","Quantizing layer:network.1.weight , with weights shape:torch.Size([32])\n","Final error of W quantization: 5.127986431121826\n","\n","Quantizing layer:network.3.weight , with weights shape:torch.Size([64, 32, 3, 3])\n","Final error of W quantization: 23.36138916015625\n","\n","Quantizing layer:network.7.weight , with weights shape:torch.Size([128, 64, 3, 3])\n","Final error of W quantization: 47.049110412597656\n","\n","Quantizing layer:network.8.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 11.08896541595459\n","\n","Quantizing layer:network.11.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 67.48347473144531\n","\n","Quantizing layer:network.12.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 10.400452613830566\n","\n","Quantizing layer:network.15.weight , with weights shape:torch.Size([256, 128, 3, 3])\n","Final error of W quantization: 92.42082214355469\n","\n","Quantizing layer:network.16.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 13.976985931396484\n","\n","Quantizing layer:network.18.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 134.9881134033203\n","\n","Quantizing layer:network.19.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 8.286518096923828\n","\n","Quantizing layer:network.24.weight , with weights shape:torch.Size([512, 4096])\n","Final error of W quantization: 39.315860748291016\n","\n","Quantizing layer:network.26.weight , with weights shape:torch.Size([100, 512])\n","Final error of W quantization: 11.060406684875488\n","--------Results appended for cifar_cnn_model.pt with precision 2\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9343e58101a1449fb3327548653e591a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54faf59af68a4e918d1a996cbf155428","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfe6cb2e322c4ce69a53378eaafb4130","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11a37d606e564ff08fd38cdd3660f615","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","                model quant_method precision  ... train_acc  test_loss  test_acc\n","0  cifar_cnn_model.pt  multi-point        32  ...   0.58748   2.022032    0.4603\n","1  cifar_cnn_model.pt  multi-point         2  ...   0.01000   4.627048    0.0100\n","\n","[2 rows x 8 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yes0ALHOiMrb"},"source":["# **Model = Resnet9, Data = CIFAR100 data**\n","Val Accuracy=60%\n","\n"]},{"cell_type":"code","metadata":{"id":"6ibauJn8iLxz","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["d4f533576e4345898b1cc2dbcf5da193","afa0e4b98d124ad08fccd179a46aa6d1","b687b48d52814d7ba691d5c793ed662e","de06568d02744c178bf541bdb5a77daa","9e43344d5e7146d9af395e8fe3d3d429","5cf81b50134448f09ad901cef4440afd","ae987a64c3ce4140b9a277e323ab3f50","86fa430f355b4c05a427c2f58d34c42c","b1af47ea8e5c4a8bae4f84c1c856576a","e115d59e25dc4189a0842ef31a899284","54525c22524b4bf7bc4824f973d58e9d","3360cfbb41004e35977f3ef1714fb283","4e9fa7e4af7d458781d1d9fe1e4c53cf","456c1a3340ff4052a334ca91fc5c3be9","2f6b1ba6b64841d6bc969f6f787a70f0","9303a5b25bac4b869663939d3c6a4bd0","0a351256d3e4456b9bb220459a83f24b","c1ce012599814315ba1c676115c0cec6","47f5a6daa2984408b2c52bd74903d627","e89edb89cb5a44c78547c4c7ba2bb139","a44b442f9e504152b059278a7dd78a69","9485fac4581646d09f698b25ad953e09","fb719cc17a5f405f8d43e39151409570","0267e5751788430cab9ad9737c0139ed","417fcf763fa744ccbfa5f4858ab9b6ac","fef201efddca4f45ba5fa35d7e2e0a52","cf58a3e7a3dd49cba0f932fca2e521ee","2b17414b8c6848658dddd103092a9b3b","fe694402f17f4e76b3e6689a2f57118d","75710795934049fab80e41f171c5e214","ffa908166bb04bb8968e64c8ffc21b76","881c09ba38684e03b1f8988d5419395c","5c0020db454d427a95bc8ed9c5bd4b44","7504ac6f682f443487ea1c102fb501aa","8289c948cc0540e2bd4c99fa98f6048c","53fb7eb41a254404bb084e43a82df985","b9016f06530f46af90273c21ed340972","b79d835fdcd04fe3b43b57ed2130a946","20545ae8e0c24042bd6e74a7cba8d9b6","491af09bd1e5449fa030d53d91b69e47"]},"executionInfo":{"status":"ok","timestamp":1605858657053,"user_tz":480,"elapsed":76024,"user":{"displayName":"Kumari Nishu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFdfS8IitH2P71X64Sf8cglHIG79P672a7SbQD=s64","userId":"13793804378645653224"}},"outputId":"c9ac6e74-7a7d-46da-d6fe-952aed37dfab"},"source":["# %%writefile train_cifar.py\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchsummary import summary\n","\n","from model.dnn import DenseNeuralNet\n","from model.cnn import CNN_resnet9\n","from data.churn_data import ChurnDataset\n","from data.telescope_data import TelescopeDataset\n","from utils.post_training_quantization import *\n","from data.mv_data import MVDataset\n","from tqdm.auto import trange, tqdm\n","from tqdm import trange\n","from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","\n","\n","def get_cifar100_dataset(train = True):\n","  transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.5071, 0.4865, 0.4409), std=(0.2673, 0.2564, 0.2762)),\n","  ])\n","\n","  transform_test = transforms.Compose([\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=(0.5071, 0.4865, 0.4409), std=(0.2673, 0.2564, 0.2762)),\n","  ])\n","\n","  if train == True:\n","      dataset = datasets.CIFAR100(root = './data', train = train, transform=transform_test, target_transform=None, download=True)\n","  else:\n","      dataset = datasets.CIFAR100(root = './data', train = train, transform=transform_test, target_transform=None, download=True)\n","  \n","  return dataset\n","\n","\n","def get_accuracy(logits, labels):\n","  preds = torch.argmax(logits, axis=1)\n","  matches = preds == labels\n","  return (matches.sum(), len(labels))\n","\n","\n","def evaluate(model, test_set, batch_size, criterion, ep = 0):\n","  test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, shuffle=True, num_workers=1)\n","  test_iterator = tqdm(test_loader, desc = 'Eval Iteration for epoch:'+str(ep+1), ncols = 900)\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  \n","  model.eval()\n","  global_step = 0\n","  total_correct = 0\n","  total_samples = 0\n","  total_loss = 0.0\n","  with torch.no_grad():\n","    for step, inputs in enumerate(test_iterator):\n","      global_step +=1\n","      # if global_step > 500:\n","      #   break\n","      x, y = inputs[0].to(device), inputs[1].long().to(device)\n","\n","      logits = model(x)\n","      loss = criterion(logits, y)\n","      correct, samples = get_accuracy(logits, y)\n","      total_correct +=correct.item()\n","      total_samples +=samples\n","      total_loss +=loss\n","  # print(total_correct, total_samples)\n","  acc = total_correct / total_samples\n","  total_loss = total_loss / global_step\n","  model.train()\n","  \n","  return (total_loss, acc)\n","\n","\n","max_lr = 0.01\n","grad_clip = 0.1\n","weight_decay = 1e-5\n","\n","def train(model, train_set, val_set, test_set , batch_size = 16, learning_rate = 0.03, epochs = 5, eval_steps = 10, skip_train_set = True):\n","  # logging\n","  train_log = open(\"log/cifar_resnet9_train.log\", \"a\")\n","  val_log = open(\"log/cifar_resnet9_val.log\", \"a\")\n","  test_log = open(\"log/cifar_resnet9_test.log\", \"a\")\n","\n","  # GPU/CPU use\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(\"Device: \", device)\n","  model = model.to(device)\n","  print(\"Model Summary:\")\n","  summary(model, next(iter(train_set))[0].shape)\n","\n","  # trainloader\n","  train_loader = torch.utils.data.DataLoader(dataset= train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n","  \n","  # define loss & optimizer\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n","  sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n","                                                steps_per_epoch=len(train_loader))\n","  # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","\n","  # iterate over epoch\n","  global_step = 0\n","  for ep in tqdm(range(epochs), desc = ' Epoch Progress:', ncols=900):\n","    train_iterator = tqdm(train_loader, desc = 'Train Iteration for epoch:'+ str(ep+1), ncols=900)    \n","    running_loss = 0\n","\n","    # iterate over batches\n","    for step, inputs in enumerate(train_iterator):\n","      model.train()\n","      global_step +=1\n","      optimizer.zero_grad()\n","      # predict, find loss, get grads, update weight\n","      x, y = inputs[0].to(device), inputs[1].to(device)\n","      logits = model(x)\n","      loss = criterion(logits, y)\n","      loss.backward()\n","      nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","      optimizer.step()\n","      sched.step()\n","      running_loss+=loss.item()\n","\n","    # find validation accuracy\n","    val_loss, val_accuracy = evaluate(model, val_set, batch_size, criterion, ep)\n","    val_log.write(\"Epoch = {}, validation loss =  {}, validation accuracy = {} \\n\".format(ep+1, val_loss, val_accuracy))\n","    print(\"Step = %d, validation loss =  %.3f, validation accuracy = %.3f\" %(global_step, val_loss, val_accuracy))\n","    \n","    # find train accuracy if needed\n","    if not skip_train_set:\n","      train_loss , train_accuracy = evaluate(model, train_set, batch_size, criterion, ep)\n","      train_log.write(\"Epoch = {}, training loss =  {}, training accuracy = {} \\n\".format(ep+1, train_loss, train_accuracy))\n","      print(\"Step = %d, training loss =  %.3f, training accuracy = %.3f\" %(global_step, train_loss, train_accuracy))\n","\n","  # find test accuracy with final model\n","  if test_set is not None:  \n","    test_loss, test_accuracy = evaluate(model, test_set, batch_size, criterion, ep)\n","    test_log.write(\"End of training, test loss =  {}, test accuracy = {} \\n\".format(test_loss, test_accuracy))\n","    print(\"End of Training, test loss =  %.3f, test accuracy = %.3f\" %(test_loss, test_accuracy))\n","\n","  # close log files\n","  train_log.close()\n","  val_log.close()\n","  test_log.close()\n","\n","def main(train_model, quantize):\n","  ### config params\n","  output_classes = 100\n","  learning_rate = 0.001\n","  batch_size = 16\n","  epochs = 10\n","  eval_steps = 100\n","  model_dir = 'model_artifacts'\n","  model_name = 'cifar_resnet9_model.pt'\n","  criterion = nn.CrossEntropyLoss()\n","  ####\n","\n","  train_set, val_set, test_set = None, None, None\n","  train_set = get_cifar100_dataset(train = True)\n","  val_set = get_cifar100_dataset(train = False)\n","  \n","  if train_model:\n","    model = CNN_resnet9(output_classes)\n","    train(model, train_set, val_set, test_set , batch_size = batch_size, learning_rate = learning_rate, epochs = epochs, eval_steps = eval_steps, skip_train_set = True)\n","    torch.save(model, os.path.join(model_dir, model_name))\n","  else:\n","    model = torch.load(os.path.join(model_dir, model_name))\n","    val_loss, val_accuracy = evaluate(model, val_set, batch_size, criterion)\n","    print(\"Running evaluation on loaded model, validation loss = %f, validation accuracy = %f\"%(val_loss, val_accuracy))\n","\n","\n","  if quantize:\n","    path_result = \"data/results/multipoint/\"\n","    # Choose Quantization method\n","    results = multipoint_quantization.multipoint_quantization(model_name, precision=[2])\n","    # results = quantization(model_name, method='all')\n","\n","    # Evaluate quantized models\n","    model_results = quantization_eval_results(results,train_set,val_set,batch_size,criterion)\n","    model_results.to_csv(path_result + model_name[:-3]+'_multipoint2' +\".csv\")\n","    print(model_results)\n","\n","\n","if __name__ == \"__main__\":\n","  main(train_model=False, quantize=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4f533576e4345898b1cc2dbcf5da193","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Running evaluation on loaded model, validation loss = 1.599502, validation accuracy = 0.597900\n","\n","--------Quantizing the model cifar_resnet9_model.pt with precision 2\n","All layers except bias layers:  ['conv1.0.weight', 'conv1.1.weight', 'conv2.0.weight', 'conv2.1.weight', 'res1.0.0.weight', 'res1.0.1.weight', 'res1.1.0.weight', 'res1.1.1.weight', 'conv3.0.weight', 'conv3.1.weight', 'conv4.0.weight', 'conv4.1.weight', 'res2.0.0.weight', 'res2.0.1.weight', 'res2.1.0.weight', 'res2.1.1.weight', 'classifier.2.weight']\n","\n","Quantizing layer:conv1.1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 9.3154935836792\n","\n","Quantizing layer:conv2.0.weight , with weights shape:torch.Size([128, 64, 3, 3])\n","Final error of W quantization: 65.13798522949219\n","\n","Quantizing layer:conv2.1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 15.2453031539917\n","\n","Quantizing layer:res1.0.0.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 49.3735466003418\n","\n","Quantizing layer:res1.0.1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 10.471117973327637\n","\n","Quantizing layer:res1.1.0.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 46.53633117675781\n","\n","Quantizing layer:res1.1.1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 9.45704460144043\n","\n","Quantizing layer:conv3.0.weight , with weights shape:torch.Size([256, 128, 3, 3])\n","Final error of W quantization: 85.13050842285156\n","\n","Quantizing layer:conv3.1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 15.570372581481934\n","\n","Quantizing layer:conv4.0.weight , with weights shape:torch.Size([512, 256, 3, 3])\n","Final error of W quantization: 153.2974395751953\n","\n","Quantizing layer:conv4.1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 14.438752174377441\n","\n","Quantizing layer:res2.0.0.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 37.440940856933594\n","\n","Quantizing layer:res2.0.1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 8.100821495056152\n","\n","Quantizing layer:res2.1.0.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 17.178916931152344\n","\n","Quantizing layer:res2.1.1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 3.191037893295288\n","\n","Quantizing layer:classifier.2.weight , with weights shape:torch.Size([100, 512])\n","Final error of W quantization: 75.54923248291016\n","--------Results appended for cifar_resnet9_model.pt with precision 2\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1af47ea8e5c4a8bae4f84c1c856576a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a351256d3e4456b9bb220459a83f24b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"417fcf763fa744ccbfa5f4858ab9b6ac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c0020db454d427a95bc8ed9c5bd4b44","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","                    model quant_method  ... test_loss test_acc\n","0  cifar_resnet9_model.pt  multi-point  ...  1.599501   0.5979\n","1  cifar_resnet9_model.pt  multi-point  ...  5.075922   0.0100\n","\n","[2 rows x 8 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9D1FU_OG79H8"},"source":["# **Model = Resnet50, Data = CIFAR100 data**\n","Val Accuracy=50%"]},{"cell_type":"code","metadata":{"id":"IGosTpnZ9DqW","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e4e36c69798f4fd1adb5f8dca5d26b4c","a3801bc126a4418981117c075f399459","ccc3a42cc0f24eaa9a2d9aa0ae5b96c1","791c97d79dfc42769815c195346e3940","3a55e569e3554b658824458be0c0f11b","244384b017f94c36994e5739d95f38d9","1c98cb114af54f60855b80271025c15a","f02a4f6978774de4990e7a07580a9a41","44d86609934c44ed99467a35d1b84cad","430f7077235c4ac3a996e616f1e9b7a7","ad10ff76531f4877b5ab3003dc664f3e","374e8dec900d493296accdc6b001d9f8","2336c4c03824435f869fe39b57dbe898","53a161df98134cec89c72014d357e88f","144b5ba611ec413183b6796c9aa49ad5","649bcdf40ca84fc785cd38534c814258","98f568eca51e4742ab208122e20be751","196b58571f3b4b839a731444904648e8","72aa6365dceb427fa7d11f7f75355ff3","316a88c4c838468399a0c59467deb500","4bd9cf0a84674814a52baf55cba4204c","1361585476434ddb9af31cace8a1f4bd","8c27721dd8a242e3868fcd25e699b286","f862de0da7f64033ba6a1871ca74502b","432a0766346443868154bddd7a3351ba","6c96dfa2dd4645b3862e319b76f8fd7b","2789700d8a804061a4e9862f49ee4522","4e3c8cdba5a34770ac3005164e5e7b1d","28f0e58f55634d7fa32f4ca2b9b2f4d8","70ec434313364a4fafd40364c5f53415","1156eabf9a0346b3b44e34be420cbc99","95f99527ff834aa6acfd8a752418b050","fbed456b67f54a8c960d6d9f0ded9e5f","82038eebc5ed4edb97fe87e88fac2e2e","c3769fe8e9db41e683d56b687e05568b","94d44edf6bfb42afb34cb1586e3e07d8","9d9f8869dd364111a35aee8972532a98","4610c693509c468c9d269119aae4c4ee","41ca6c52c38b4ae79fe7a07b27344912","5ac8bb7eecd64ddd894cf030f6c4a409","88d762f810684c008b6e04292a88e11f","2c08c20d4b374065a4bd92e013cab9fc","702b15a9c96e4506adb5bd1c06c79192","5654af108c394a06b83fc46ad3e608f3","f5fee20332544a3c82f04110989aef74","98b759f47d894290bd75f685661fdc5a","22460ffadd6443ae9d11a55c32b5fc45","1986bb03aa3943dd9e16ce30336c5f13","b944d0c1aaa84e1c9954522f80eb3717","ec1033f7886a4be1ba18ef7b688ab866","6b6826111b044951bf6bb3f2d232beaa","a5f7b0acc3c247e0b2874eacff7405b0","66988e13240c4b499027bcfa01bff41f","b5062a5b158f4842bea47a2db9c00504","879ea73d093a4bda8ed4cc472aed7e48","e2124a996e81419898012034a9fcfc94","2bbae422112a4f068c6e711ee8c2d694","bf3529bcc08d4f1d8432ef6fd5898fa3","4670212ce6e24c389237b8cf10833e06","6fb9d2cd2d6044478958c7e5761d533a","48107a86e5a04d3db304306d965bbb00","51684a9bbb9849f1a7c4a00bb516aaae","229d0ad4baae443bb3f53bc08b30864b","7dd9822fbb8047f1bea595267863caf0","d6509e3ba55a4a0683414c65c45c7914","4e2543b3202143c6b13014f181a2b0a2","f199fb10447b4b0293b90abbfac09744","1590d64c86c34acebe7407df8a1c813f","5e67010baa974d2484758d37a0c5bcfd","b66796895fc04194ae529c4dd0361fc5","0d5f12fd843648bb92c26f82f2160095","e87ae72498334839bf4e4a45aed366ad","43ff4da758b742679d68c52c5701004e","b7a3680fe6c64686a40fcc8faeae4ee6","2a4e3fe41cd349d38443c6e2e36e3a22","8860321f61cb4c66bb943d1e8d82155e","830bdbef77d84521bb138bacc5138ddf","b972eba934e740c9b5991f00354e00cc","4556a7a390034077b970b1c9679f15be","19d185c94ec94583abeeeda340efd5dd","3c85ee8b3eb348d396ab6c81e5388cc1","5eff4b5a0f0041b09f6bb7359a160842","e18673429c7c479284db2e5fed3ac7a6","6d1b0997597f44f18a379b5595c447c5","2010f00d28404b2abc7d07b450370485","c5705b9e787a4cc0a787448012d00e6d","24532cbffac040ae96328a927fb7936e","f52e370157bf4b83866c328ccff69fc6"]},"executionInfo":{"status":"ok","timestamp":1605821031614,"user_tz":480,"elapsed":1338655,"user":{"displayName":"Kumari Nishu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFdfS8IitH2P71X64Sf8cglHIG79P672a7SbQD=s64","userId":"13793804378645653224"}},"outputId":"6870df8d-681b-42d4-d8a1-b84ca3f3bee3"},"source":["# %%writefile train_cifar.py\n","import time\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchsummary import summary\n","\n","from model.dnn import DenseNeuralNet\n","from model.cnn import CNN_resnet50\n","from utils.post_training_quantization import *\n","from data.mv_data import MVDataset\n","from tqdm.auto import trange, tqdm\n","from tqdm import trange\n","from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","\n","\n","def get_cifar100_dataset(train = True):\n","  transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","  ])\n","\n","  transform_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","  ])\n","\n","  if train == True:\n","      dataset = datasets.CIFAR100(root = './data', train = train, transform=transform_test, target_transform=None, download=True)\n","  else:\n","      dataset = datasets.CIFAR100(root = './data', train = train, transform=transform_test, target_transform=None, download=True)\n","  \n","  return dataset\n","\n","\n","def get_accuracy(logits, labels):\n","  preds = torch.argmax(logits, axis=1)\n","  matches = preds == labels\n","  return (matches.sum(), len(labels))\n","\n","\n","def evaluate(model, test_set, batch_size, criterion, ep = 0):\n","  test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, shuffle=True, num_workers=1)\n","  test_iterator = tqdm(test_loader, desc = 'Eval Iteration for epoch:'+str(ep+1), ncols = 900)\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  \n","  model.eval()\n","  global_step = 0\n","  total_correct = 0\n","  total_samples = 0\n","  total_loss = 0.0\n","  with torch.no_grad():\n","    for step, inputs in enumerate(test_iterator):\n","      global_step +=1\n","      # if global_step > 500:\n","      #   break\n","      x, y = inputs[0].to(device), inputs[1].long().to(device)\n","\n","      logits = model(x)\n","      loss = criterion(logits, y)\n","      correct, samples = get_accuracy(logits, y)\n","      total_correct +=correct.item()\n","      total_samples +=samples\n","      total_loss +=loss\n","  # print(total_correct, total_samples)\n","  acc = total_correct / total_samples\n","  total_loss = total_loss / global_step\n","  model.train()\n","  \n","  return (total_loss, acc)\n","\n","\n","def train(model, train_set, val_set, test_set , batch_size = 16, learning_rate = 0.03, epochs = 5, eval_steps = 10, skip_train_set = True):\n","  # logging\n","  train_log = open(\"log/cifar_resnet50_train.log\", \"a\")\n","  val_log = open(\"log/cifar_resnet50_val.log\", \"a\")\n","  test_log = open(\"log/cifar_resnet50_test.log\", \"a\")\n","\n","  # GPU/CPU use\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(\"Device: \", device)\n","  model = model.to(device)\n","  print(\"Model Summary:\")\n","  summary(model, next(iter(train_set))[0].shape)\n","  \n","  # define loss & optimizer\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","  # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","\n","  # iterate over epoch\n","  train_loader = torch.utils.data.DataLoader(dataset= train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n","  global_step = 0\n","  for ep in tqdm(range(epochs), desc = ' Epoch Progress:', ncols=900):\n","    train_iterator = tqdm(train_loader, desc = 'Train Iteration for epoch:'+ str(ep+1), ncols=900)    \n","    running_loss = 0\n","\n","    # iterate over batches\n","    for step, inputs in enumerate(train_iterator):\n","      model.train()\n","      global_step +=1\n","      optimizer.zero_grad()\n","      # predict, find loss, get grads, update weight\n","      x, y = inputs[0].to(device), inputs[1].to(device)\n","      logits = model(x)\n","      loss = criterion(logits, y)\n","      loss.backward()\n","      optimizer.step()\n","      running_loss+=loss.item()\n","\n","    # find validation accuracy\n","    val_loss, val_accuracy = evaluate(model, val_set, batch_size, criterion, ep)\n","    val_log.write(\"Epoch = {}, validation loss =  {}, validation accuracy = {} \\n\".format(ep+1, val_loss, val_accuracy))\n","    print(\"Step = %d, validation loss =  %.3f, validation accuracy = %.3f\" %(global_step, val_loss, val_accuracy))\n","    \n","    # find train accuracy if needed\n","    if not skip_train_set:\n","      train_loss , train_accuracy = evaluate(model, train_set, batch_size, criterion, ep)\n","      train_log.write(\"Epoch = {}, training loss =  {}, training accuracy = {} \\n\".format(ep+1, train_loss, train_accuracy))\n","      print(\"Step = %d, training loss =  %.3f, training accuracy = %.3f\" %(global_step, train_loss, train_accuracy))\n","\n","  # find test accuracy with final model\n","  if test_set is not None:  \n","    test_loss, test_accuracy = evaluate(model, test_set, batch_size, criterion, ep)\n","    test_log.write(\"End of training, test loss =  {}, test accuracy = {} \\n\".format(test_loss, test_accuracy))\n","    print(\"End of Training, test loss =  %.3f, test accuracy = %.3f\" %(test_loss, test_accuracy))\n","\n","  # close log files\n","  train_log.close()\n","  val_log.close()\n","  test_log.close()\n","\n","def main(train_model, quantize):\n","  ### config params\n","  output_classes = 100\n","  learning_rate = 0.0009\n","  batch_size = 16\n","  epochs = 10\n","  eval_steps = 100\n","  model_dir = 'model_artifacts'\n","  model_name = 'cifar_resnet50_model.pt'\n","  criterion = nn.CrossEntropyLoss()\n","  ####\n","\n","  train_set, val_set, test_set = None, None, None\n","  train_set = get_cifar100_dataset(train = True)\n","  val_set = get_cifar100_dataset(train = False)\n","\n","  if train_model:\n","    model = CNN_resnet50(output_classes)\n","    train(model, train_set, val_set, test_set , batch_size = batch_size, learning_rate = learning_rate, epochs = epochs, eval_steps = eval_steps, skip_train_set = True)\n","    torch.save(model, os.path.join(model_dir, model_name))\n","  else:\n","    model = torch.load(os.path.join(model_dir, model_name))\n","    val_loss, val_accuracy = evaluate(model, val_set, batch_size, criterion)\n","    print(\"Running evaluation on loaded model, validation loss = %f, validation accuracy = %f\"%(val_loss, val_accuracy))\n","\n","\n","  if quantize:\n","    path_result = \"data/results/multipoint/\"\n","    # Choose Quantization method\n","    results = multipoint_quantization.multipoint_quantization(model_name, precision=[8,6,4,2])\n","    # results = quantization(model_name, method='all')\n","\n","    # Evaluate quantized models\n","    model_results = quantization_eval_results(results,train_set,val_set,batch_size,criterion)\n","    model_results.to_csv(path_result + model_name[:-3]+'_multipoint2' +\".csv\")\n","    print(model_results)\n","\n","\n","if __name__ == \"__main__\":\n","  main(train_model=False, quantize=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4e36c69798f4fd1adb5f8dca5d26b4c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Running evaluation on loaded model, validation loss = 1.780087, validation accuracy = 0.502900\n","Files already downloaded and verified\n","\n","--------Quantizing the model cifar_resnet50_model.pt with precision 8\n","All layers:  ['network.conv1.weight', 'network.bn1.weight', 'network.layer1.0.conv1.weight', 'network.layer1.0.bn1.weight', 'network.layer1.0.conv2.weight', 'network.layer1.0.bn2.weight', 'network.layer1.0.conv3.weight', 'network.layer1.0.bn3.weight', 'network.layer1.0.downsample.0.weight', 'network.layer1.0.downsample.1.weight', 'network.layer1.1.conv1.weight', 'network.layer1.1.bn1.weight', 'network.layer1.1.conv2.weight', 'network.layer1.1.bn2.weight', 'network.layer1.1.conv3.weight', 'network.layer1.1.bn3.weight', 'network.layer1.2.conv1.weight', 'network.layer1.2.bn1.weight', 'network.layer1.2.conv2.weight', 'network.layer1.2.bn2.weight', 'network.layer1.2.conv3.weight', 'network.layer1.2.bn3.weight', 'network.layer2.0.conv1.weight', 'network.layer2.0.bn1.weight', 'network.layer2.0.conv2.weight', 'network.layer2.0.bn2.weight', 'network.layer2.0.conv3.weight', 'network.layer2.0.bn3.weight', 'network.layer2.0.downsample.0.weight', 'network.layer2.0.downsample.1.weight', 'network.layer2.1.conv1.weight', 'network.layer2.1.bn1.weight', 'network.layer2.1.conv2.weight', 'network.layer2.1.bn2.weight', 'network.layer2.1.conv3.weight', 'network.layer2.1.bn3.weight', 'network.layer2.2.conv1.weight', 'network.layer2.2.bn1.weight', 'network.layer2.2.conv2.weight', 'network.layer2.2.bn2.weight', 'network.layer2.2.conv3.weight', 'network.layer2.2.bn3.weight', 'network.layer2.3.conv1.weight', 'network.layer2.3.bn1.weight', 'network.layer2.3.conv2.weight', 'network.layer2.3.bn2.weight', 'network.layer2.3.conv3.weight', 'network.layer2.3.bn3.weight', 'network.layer3.0.conv1.weight', 'network.layer3.0.bn1.weight', 'network.layer3.0.conv2.weight', 'network.layer3.0.bn2.weight', 'network.layer3.0.conv3.weight', 'network.layer3.0.bn3.weight', 'network.layer3.0.downsample.0.weight', 'network.layer3.0.downsample.1.weight', 'network.layer3.1.conv1.weight', 'network.layer3.1.bn1.weight', 'network.layer3.1.conv2.weight', 'network.layer3.1.bn2.weight', 'network.layer3.1.conv3.weight', 'network.layer3.1.bn3.weight', 'network.layer3.2.conv1.weight', 'network.layer3.2.bn1.weight', 'network.layer3.2.conv2.weight', 'network.layer3.2.bn2.weight', 'network.layer3.2.conv3.weight', 'network.layer3.2.bn3.weight', 'network.layer3.3.conv1.weight', 'network.layer3.3.bn1.weight', 'network.layer3.3.conv2.weight', 'network.layer3.3.bn2.weight', 'network.layer3.3.conv3.weight', 'network.layer3.3.bn3.weight', 'network.layer3.4.conv1.weight', 'network.layer3.4.bn1.weight', 'network.layer3.4.conv2.weight', 'network.layer3.4.bn2.weight', 'network.layer3.4.conv3.weight', 'network.layer3.4.bn3.weight', 'network.layer3.5.conv1.weight', 'network.layer3.5.bn1.weight', 'network.layer3.5.conv2.weight', 'network.layer3.5.bn2.weight', 'network.layer3.5.conv3.weight', 'network.layer3.5.bn3.weight', 'network.layer4.0.conv1.weight', 'network.layer4.0.bn1.weight', 'network.layer4.0.conv2.weight', 'network.layer4.0.bn2.weight', 'network.layer4.0.conv3.weight', 'network.layer4.0.bn3.weight', 'network.layer4.0.downsample.0.weight', 'network.layer4.0.downsample.1.weight', 'network.layer4.1.conv1.weight', 'network.layer4.1.bn1.weight', 'network.layer4.1.conv2.weight', 'network.layer4.1.bn2.weight', 'network.layer4.1.conv3.weight', 'network.layer4.1.bn3.weight', 'network.layer4.2.conv1.weight', 'network.layer4.2.bn1.weight', 'network.layer4.2.conv2.weight', 'network.layer4.2.bn2.weight', 'network.layer4.2.conv3.weight', 'network.layer4.2.bn3.weight', 'network.fc.0.weight', 'network.fc.2.weight']\n","\n","Quantizing layer:network.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.004312578123062849\n","\n","Quantizing layer:network.layer1.0.conv1.weight , with weights shape:torch.Size([64, 64, 1, 1])\n","Final error of W quantization: 0.11564527451992035\n","\n","Quantizing layer:network.layer1.0.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.0176240261644125\n","\n","Quantizing layer:network.layer1.0.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 0.06545717269182205\n","\n","Quantizing layer:network.layer1.0.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.03458742797374725\n","\n","Quantizing layer:network.layer1.0.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 0.060886044055223465\n","\n","Quantizing layer:network.layer1.0.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.025265097618103027\n","\n","Quantizing layer:network.layer1.0.downsample.0.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 0.001592472312040627\n","\n","Quantizing layer:network.layer1.0.downsample.1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.00976456981152296\n","\n","Quantizing layer:network.layer1.1.conv1.weight , with weights shape:torch.Size([64, 256, 1, 1])\n","Final error of W quantization: 0.09749172627925873\n","\n","Quantizing layer:network.layer1.1.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.02126283012330532\n","\n","Quantizing layer:network.layer1.1.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 0.035352226346731186\n","\n","Quantizing layer:network.layer1.1.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.02382134459912777\n","\n","Quantizing layer:network.layer1.1.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 0.13405942916870117\n","\n","Quantizing layer:network.layer1.1.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.047432791441679\n","\n","Quantizing layer:network.layer1.2.conv1.weight , with weights shape:torch.Size([64, 256, 1, 1])\n","Final error of W quantization: 0.26556041836738586\n","\n","Quantizing layer:network.layer1.2.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.04088335484266281\n","\n","Quantizing layer:network.layer1.2.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 0.07168707996606827\n","\n","Quantizing layer:network.layer1.2.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.017463549971580505\n","\n","Quantizing layer:network.layer1.2.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 0.09002206474542618\n","\n","Quantizing layer:network.layer1.2.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.03911443427205086\n","\n","Quantizing layer:network.layer2.0.conv1.weight , with weights shape:torch.Size([128, 256, 1, 1])\n","Final error of W quantization: 0.06932356208562851\n","\n","Quantizing layer:network.layer2.0.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.017246002331376076\n","\n","Quantizing layer:network.layer2.0.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 0.26458603143692017\n","\n","Quantizing layer:network.layer2.0.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.03031899966299534\n","\n","Quantizing layer:network.layer2.0.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 0.07141982764005661\n","\n","Quantizing layer:network.layer2.0.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.04715999588370323\n","\n","Quantizing layer:network.layer2.0.downsample.0.weight , with weights shape:torch.Size([512, 256, 1, 1])\n","Final error of W quantization: 0.03869757428765297\n","\n","Quantizing layer:network.layer2.0.downsample.1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.039838291704654694\n","\n","Quantizing layer:network.layer2.1.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 0.12134896963834763\n","\n","Quantizing layer:network.layer2.1.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.05788306146860123\n","\n","Quantizing layer:network.layer2.1.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 0.139979749917984\n","\n","Quantizing layer:network.layer2.1.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.027255969122052193\n","\n","Quantizing layer:network.layer2.1.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 0.12331609427928925\n","\n","Quantizing layer:network.layer2.1.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.03408004343509674\n","\n","Quantizing layer:network.layer2.2.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 0.28450801968574524\n","\n","Quantizing layer:network.layer2.2.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.04878118261694908\n","\n","Quantizing layer:network.layer2.2.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 0.1603713184595108\n","\n","Quantizing layer:network.layer2.2.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.02771676890552044\n","\n","Quantizing layer:network.layer2.2.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 0.06649574637413025\n","\n","Quantizing layer:network.layer2.2.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.05103996768593788\n","\n","Quantizing layer:network.layer2.3.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 0.0719398632645607\n","\n","Quantizing layer:network.layer2.3.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.047104209661483765\n","\n","Quantizing layer:network.layer2.3.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 0.09578441083431244\n","\n","Quantizing layer:network.layer2.3.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.0499517098069191\n","\n","Quantizing layer:network.layer2.3.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 0.10546571761369705\n","\n","Quantizing layer:network.layer2.3.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.04075019061565399\n","\n","Quantizing layer:network.layer3.0.conv1.weight , with weights shape:torch.Size([256, 512, 1, 1])\n","Final error of W quantization: 0.1215415745973587\n","\n","Quantizing layer:network.layer3.0.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.029285721480846405\n","\n","Quantizing layer:network.layer3.0.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 0.3156754672527313\n","\n","Quantizing layer:network.layer3.0.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.022100035101175308\n","\n","Quantizing layer:network.layer3.0.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.08585921674966812\n","\n","Quantizing layer:network.layer3.0.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 0.02758171409368515\n","\n","Quantizing layer:network.layer3.0.downsample.0.weight , with weights shape:torch.Size([1024, 512, 1, 1])\n","Final error of W quantization: 0.07208260148763657\n","\n","Quantizing layer:network.layer3.0.downsample.1.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 0.06548254936933517\n","\n","Quantizing layer:network.layer3.1.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 0.12097344547510147\n","\n","Quantizing layer:network.layer3.1.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.027291927486658096\n","\n","Quantizing layer:network.layer3.1.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 0.08672049641609192\n","\n","Quantizing layer:network.layer3.1.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.018983880057930946\n","\n","Quantizing layer:network.layer3.1.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.05369554087519646\n","\n","Quantizing layer:network.layer3.1.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 0.02809884399175644\n","\n","Quantizing layer:network.layer3.2.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 0.08662182837724686\n","\n","Quantizing layer:network.layer3.2.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.06394696235656738\n","\n","Quantizing layer:network.layer3.2.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 0.18597324192523956\n","\n","Quantizing layer:network.layer3.2.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.022105246782302856\n","\n","Quantizing layer:network.layer3.2.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.09073653817176819\n","\n","Quantizing layer:network.layer3.2.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 0.07528138160705566\n","\n","Quantizing layer:network.layer3.3.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 0.1668492704629898\n","\n","Quantizing layer:network.layer3.3.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.04723680391907692\n","\n","Quantizing layer:network.layer3.3.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 0.07466647773981094\n","\n","Quantizing layer:network.layer3.3.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.03856509178876877\n","\n","Quantizing layer:network.layer3.3.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.11496281623840332\n","\n","Quantizing layer:network.layer3.3.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 0.053513482213020325\n","\n","Quantizing layer:network.layer3.4.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 0.11795713752508163\n","\n","Quantizing layer:network.layer3.4.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.03794806823134422\n","\n","Quantizing layer:network.layer3.4.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 0.17409422993659973\n","\n","Quantizing layer:network.layer3.4.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.04243996739387512\n","\n","Quantizing layer:network.layer3.4.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.06831205636262894\n","\n","Quantizing layer:network.layer3.4.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 0.11444013565778732\n","\n","Quantizing layer:network.layer3.5.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 0.0549524687230587\n","\n","Quantizing layer:network.layer3.5.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.031913936138153076\n","\n","Quantizing layer:network.layer3.5.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 0.16803142428398132\n","\n","Quantizing layer:network.layer3.5.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.007505296263843775\n","\n","Quantizing layer:network.layer3.5.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.1104755625128746\n","\n","Quantizing layer:network.layer3.5.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 0.040722139179706573\n","\n","Quantizing layer:network.layer4.0.conv1.weight , with weights shape:torch.Size([512, 1024, 1, 1])\n","Final error of W quantization: 0.1039082407951355\n","\n","Quantizing layer:network.layer4.0.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.029423724859952927\n","\n","Quantizing layer:network.layer4.0.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 0.09347233176231384\n","\n","Quantizing layer:network.layer4.0.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.02130417712032795\n","\n","Quantizing layer:network.layer4.0.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 0.09044481068849564\n","\n","Quantizing layer:network.layer4.0.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 0.00012872324441559613\n","\n","Quantizing layer:network.layer4.0.downsample.0.weight , with weights shape:torch.Size([2048, 1024, 1, 1])\n","Final error of W quantization: 0.05507884919643402\n","\n","Quantizing layer:network.layer4.0.downsample.1.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 0.00018258563068229705\n","\n","Quantizing layer:network.layer4.1.conv1.weight , with weights shape:torch.Size([512, 2048, 1, 1])\n","Final error of W quantization: 0.07623512297868729\n","\n","Quantizing layer:network.layer4.1.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.02204996347427368\n","\n","Quantizing layer:network.layer4.1.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 0.23024789988994598\n","\n","Quantizing layer:network.layer4.1.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.021643249318003654\n","\n","Quantizing layer:network.layer4.1.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 0.1622982770204544\n","\n","Quantizing layer:network.layer4.1.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 0.0001532463065814227\n","\n","Quantizing layer:network.layer4.2.conv1.weight , with weights shape:torch.Size([512, 2048, 1, 1])\n","Final error of W quantization: 0.09946081042289734\n","\n","Quantizing layer:network.layer4.2.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.008542254567146301\n","\n","Quantizing layer:network.layer4.2.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 0.3366560637950897\n","\n","Quantizing layer:network.layer4.2.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.017297569662332535\n","\n","Quantizing layer:network.layer4.2.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 0.1465778648853302\n","\n","Quantizing layer:network.layer4.2.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 0.0002625947236083448\n","\n","Quantizing layer:network.fc.0.weight , with weights shape:torch.Size([1024, 2048])\n","Final error of W quantization: 0.04959503188729286\n","\n","Quantizing layer:network.fc.2.weight , with weights shape:torch.Size([100, 1024])\n","Final error of W quantization: 0.06760405749082565\n","\n","--------Results appended for cifar_resnet50_model.pt with precision 8\n","\n","--------Quantizing the model cifar_resnet50_model.pt with precision 6\n","All layers:  ['network.conv1.weight', 'network.bn1.weight', 'network.layer1.0.conv1.weight', 'network.layer1.0.bn1.weight', 'network.layer1.0.conv2.weight', 'network.layer1.0.bn2.weight', 'network.layer1.0.conv3.weight', 'network.layer1.0.bn3.weight', 'network.layer1.0.downsample.0.weight', 'network.layer1.0.downsample.1.weight', 'network.layer1.1.conv1.weight', 'network.layer1.1.bn1.weight', 'network.layer1.1.conv2.weight', 'network.layer1.1.bn2.weight', 'network.layer1.1.conv3.weight', 'network.layer1.1.bn3.weight', 'network.layer1.2.conv1.weight', 'network.layer1.2.bn1.weight', 'network.layer1.2.conv2.weight', 'network.layer1.2.bn2.weight', 'network.layer1.2.conv3.weight', 'network.layer1.2.bn3.weight', 'network.layer2.0.conv1.weight', 'network.layer2.0.bn1.weight', 'network.layer2.0.conv2.weight', 'network.layer2.0.bn2.weight', 'network.layer2.0.conv3.weight', 'network.layer2.0.bn3.weight', 'network.layer2.0.downsample.0.weight', 'network.layer2.0.downsample.1.weight', 'network.layer2.1.conv1.weight', 'network.layer2.1.bn1.weight', 'network.layer2.1.conv2.weight', 'network.layer2.1.bn2.weight', 'network.layer2.1.conv3.weight', 'network.layer2.1.bn3.weight', 'network.layer2.2.conv1.weight', 'network.layer2.2.bn1.weight', 'network.layer2.2.conv2.weight', 'network.layer2.2.bn2.weight', 'network.layer2.2.conv3.weight', 'network.layer2.2.bn3.weight', 'network.layer2.3.conv1.weight', 'network.layer2.3.bn1.weight', 'network.layer2.3.conv2.weight', 'network.layer2.3.bn2.weight', 'network.layer2.3.conv3.weight', 'network.layer2.3.bn3.weight', 'network.layer3.0.conv1.weight', 'network.layer3.0.bn1.weight', 'network.layer3.0.conv2.weight', 'network.layer3.0.bn2.weight', 'network.layer3.0.conv3.weight', 'network.layer3.0.bn3.weight', 'network.layer3.0.downsample.0.weight', 'network.layer3.0.downsample.1.weight', 'network.layer3.1.conv1.weight', 'network.layer3.1.bn1.weight', 'network.layer3.1.conv2.weight', 'network.layer3.1.bn2.weight', 'network.layer3.1.conv3.weight', 'network.layer3.1.bn3.weight', 'network.layer3.2.conv1.weight', 'network.layer3.2.bn1.weight', 'network.layer3.2.conv2.weight', 'network.layer3.2.bn2.weight', 'network.layer3.2.conv3.weight', 'network.layer3.2.bn3.weight', 'network.layer3.3.conv1.weight', 'network.layer3.3.bn1.weight', 'network.layer3.3.conv2.weight', 'network.layer3.3.bn2.weight', 'network.layer3.3.conv3.weight', 'network.layer3.3.bn3.weight', 'network.layer3.4.conv1.weight', 'network.layer3.4.bn1.weight', 'network.layer3.4.conv2.weight', 'network.layer3.4.bn2.weight', 'network.layer3.4.conv3.weight', 'network.layer3.4.bn3.weight', 'network.layer3.5.conv1.weight', 'network.layer3.5.bn1.weight', 'network.layer3.5.conv2.weight', 'network.layer3.5.bn2.weight', 'network.layer3.5.conv3.weight', 'network.layer3.5.bn3.weight', 'network.layer4.0.conv1.weight', 'network.layer4.0.bn1.weight', 'network.layer4.0.conv2.weight', 'network.layer4.0.bn2.weight', 'network.layer4.0.conv3.weight', 'network.layer4.0.bn3.weight', 'network.layer4.0.downsample.0.weight', 'network.layer4.0.downsample.1.weight', 'network.layer4.1.conv1.weight', 'network.layer4.1.bn1.weight', 'network.layer4.1.conv2.weight', 'network.layer4.1.bn2.weight', 'network.layer4.1.conv3.weight', 'network.layer4.1.bn3.weight', 'network.layer4.2.conv1.weight', 'network.layer4.2.bn1.weight', 'network.layer4.2.conv2.weight', 'network.layer4.2.bn2.weight', 'network.layer4.2.conv3.weight', 'network.layer4.2.bn3.weight', 'network.fc.0.weight', 'network.fc.2.weight']\n","\n","Quantizing layer:network.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.5433383584022522\n","\n","Quantizing layer:network.layer1.0.conv1.weight , with weights shape:torch.Size([64, 64, 1, 1])\n","Final error of W quantization: 1.3797824382781982\n","\n","Quantizing layer:network.layer1.0.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.6994905471801758\n","\n","Quantizing layer:network.layer1.0.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 1.1015574932098389\n","\n","Quantizing layer:network.layer1.0.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.7014467716217041\n","\n","Quantizing layer:network.layer1.0.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 1.0441360473632812\n","\n","Quantizing layer:network.layer1.0.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.992257833480835\n","\n","Quantizing layer:network.layer1.0.downsample.0.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 0.4707852005958557\n","\n","Quantizing layer:network.layer1.0.downsample.1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.2221237421035767\n","\n","Quantizing layer:network.layer1.1.conv1.weight , with weights shape:torch.Size([64, 256, 1, 1])\n","Final error of W quantization: 1.2414629459381104\n","\n","Quantizing layer:network.layer1.1.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.6633905172348022\n","\n","Quantizing layer:network.layer1.1.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 0.4327869713306427\n","\n","Quantizing layer:network.layer1.1.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.6846404075622559\n","\n","Quantizing layer:network.layer1.1.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 1.3424885272979736\n","\n","Quantizing layer:network.layer1.1.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.816337525844574\n","\n","Quantizing layer:network.layer1.2.conv1.weight , with weights shape:torch.Size([64, 256, 1, 1])\n","Final error of W quantization: 2.083296537399292\n","\n","Quantizing layer:network.layer1.2.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.8650190830230713\n","\n","Quantizing layer:network.layer1.2.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 1.266728162765503\n","\n","Quantizing layer:network.layer1.2.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 0.8362782001495361\n","\n","Quantizing layer:network.layer1.2.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 1.3946681022644043\n","\n","Quantizing layer:network.layer1.2.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.7517502903938293\n","\n","Quantizing layer:network.layer2.0.conv1.weight , with weights shape:torch.Size([128, 256, 1, 1])\n","Final error of W quantization: 1.2574151754379272\n","\n","Quantizing layer:network.layer2.0.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.8663280010223389\n","\n","Quantizing layer:network.layer2.0.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 2.2524619102478027\n","\n","Quantizing layer:network.layer2.0.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.152233362197876\n","\n","Quantizing layer:network.layer2.0.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 1.2273586988449097\n","\n","Quantizing layer:network.layer2.0.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 1.4079337120056152\n","\n","Quantizing layer:network.layer2.0.downsample.0.weight , with weights shape:torch.Size([512, 256, 1, 1])\n","Final error of W quantization: 0.8346141576766968\n","\n","Quantizing layer:network.layer2.0.downsample.1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 1.4227540493011475\n","\n","Quantizing layer:network.layer2.1.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 1.1260590553283691\n","\n","Quantizing layer:network.layer2.1.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.7594017386436462\n","\n","Quantizing layer:network.layer2.1.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 1.681937575340271\n","\n","Quantizing layer:network.layer2.1.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 0.8716809153556824\n","\n","Quantizing layer:network.layer2.1.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 1.556803584098816\n","\n","Quantizing layer:network.layer2.1.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 1.2191102504730225\n","\n","Quantizing layer:network.layer2.2.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 2.3213508129119873\n","\n","Quantizing layer:network.layer2.2.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.146283745765686\n","\n","Quantizing layer:network.layer2.2.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 2.0017528533935547\n","\n","Quantizing layer:network.layer2.2.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.1862671375274658\n","\n","Quantizing layer:network.layer2.2.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 1.0297645330429077\n","\n","Quantizing layer:network.layer2.2.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.9923362731933594\n","\n","Quantizing layer:network.layer2.3.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 1.0163512229919434\n","\n","Quantizing layer:network.layer2.3.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.1274704933166504\n","\n","Quantizing layer:network.layer2.3.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 2.14634370803833\n","\n","Quantizing layer:network.layer2.3.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.3257097005844116\n","\n","Quantizing layer:network.layer2.3.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 1.2231051921844482\n","\n","Quantizing layer:network.layer2.3.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 1.0308327674865723\n","\n","Quantizing layer:network.layer3.0.conv1.weight , with weights shape:torch.Size([256, 512, 1, 1])\n","Final error of W quantization: 2.0635530948638916\n","\n","Quantizing layer:network.layer3.0.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.8562259674072266\n","\n","Quantizing layer:network.layer3.0.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 3.729430675506592\n","\n","Quantizing layer:network.layer3.0.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.1328504085540771\n","\n","Quantizing layer:network.layer3.0.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 1.6824913024902344\n","\n","Quantizing layer:network.layer3.0.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 1.684772253036499\n","\n","Quantizing layer:network.layer3.0.downsample.0.weight , with weights shape:torch.Size([1024, 512, 1, 1])\n","Final error of W quantization: 1.3470772504806519\n","\n","Quantizing layer:network.layer3.0.downsample.1.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 1.6753400564193726\n","\n","Quantizing layer:network.layer3.1.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 1.1363247632980347\n","\n","Quantizing layer:network.layer3.1.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.9830818772315979\n","\n","Quantizing layer:network.layer3.1.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 1.5579113960266113\n","\n","Quantizing layer:network.layer3.1.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.5767818689346313\n","\n","Quantizing layer:network.layer3.1.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.7325515151023865\n","\n","Quantizing layer:network.layer3.1.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 0.6077749133110046\n","\n","Quantizing layer:network.layer3.2.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 1.3348476886749268\n","\n","Quantizing layer:network.layer3.2.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.4255962371826172\n","\n","Quantizing layer:network.layer3.2.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 2.105332374572754\n","\n","Quantizing layer:network.layer3.2.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.1870617866516113\n","\n","Quantizing layer:network.layer3.2.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 1.004625678062439\n","\n","Quantizing layer:network.layer3.2.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 1.4993325471878052\n","\n","Quantizing layer:network.layer3.3.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 1.7551833391189575\n","\n","Quantizing layer:network.layer3.3.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.494275450706482\n","\n","Quantizing layer:network.layer3.3.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 0.6871134638786316\n","\n","Quantizing layer:network.layer3.3.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.4779654741287231\n","\n","Quantizing layer:network.layer3.3.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.9854814410209656\n","\n","Quantizing layer:network.layer3.3.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 1.1270596981048584\n","\n","Quantizing layer:network.layer3.4.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 1.3206086158752441\n","\n","Quantizing layer:network.layer3.4.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.3712289333343506\n","\n","Quantizing layer:network.layer3.4.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 2.2199065685272217\n","\n","Quantizing layer:network.layer3.4.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.5448628664016724\n","\n","Quantizing layer:network.layer3.4.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 0.9245017766952515\n","\n","Quantizing layer:network.layer3.4.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 1.7958881855010986\n","\n","Quantizing layer:network.layer3.5.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 0.5885673761367798\n","\n","Quantizing layer:network.layer3.5.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.3678078651428223\n","\n","Quantizing layer:network.layer3.5.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 1.6848820447921753\n","\n","Quantizing layer:network.layer3.5.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 0.33201995491981506\n","\n","Quantizing layer:network.layer3.5.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 1.0876761674880981\n","\n","Quantizing layer:network.layer3.5.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 1.4183402061462402\n","\n","Quantizing layer:network.layer4.0.conv1.weight , with weights shape:torch.Size([512, 1024, 1, 1])\n","Final error of W quantization: 1.17822265625\n","\n","Quantizing layer:network.layer4.0.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.5722968578338623\n","\n","Quantizing layer:network.layer4.0.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 0.7117103934288025\n","\n","Quantizing layer:network.layer4.0.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.051015853881836\n","\n","Quantizing layer:network.layer4.0.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 0.8299385905265808\n","\n","Quantizing layer:network.layer4.0.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 1.6110963821411133\n","\n","Quantizing layer:network.layer4.0.downsample.0.weight , with weights shape:torch.Size([2048, 1024, 1, 1])\n","Final error of W quantization: 0.5953688025474548\n","\n","Quantizing layer:network.layer4.0.downsample.1.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 0.4772269129753113\n","\n","Quantizing layer:network.layer4.1.conv1.weight , with weights shape:torch.Size([512, 2048, 1, 1])\n","Final error of W quantization: 0.4854104816913605\n","\n","Quantizing layer:network.layer4.1.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.1101772785186768\n","\n","Quantizing layer:network.layer4.1.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 1.8011990785598755\n","\n","Quantizing layer:network.layer4.1.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.2469465732574463\n","\n","Quantizing layer:network.layer4.1.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 1.506783127784729\n","\n","Quantizing layer:network.layer4.1.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 1.0110971927642822\n","\n","Quantizing layer:network.layer4.2.conv1.weight , with weights shape:torch.Size([512, 2048, 1, 1])\n","Final error of W quantization: 0.7277107834815979\n","\n","Quantizing layer:network.layer4.2.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 0.3324666917324066\n","\n","Quantizing layer:network.layer4.2.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 6.970520496368408\n","\n","Quantizing layer:network.layer4.2.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 1.9794840812683105\n","\n","Quantizing layer:network.layer4.2.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 1.3390370607376099\n","\n","Quantizing layer:network.layer4.2.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 0.2657839059829712\n","\n","Quantizing layer:network.fc.0.weight , with weights shape:torch.Size([1024, 2048])\n","Final error of W quantization: 3.2318203449249268\n","\n","Quantizing layer:network.fc.2.weight , with weights shape:torch.Size([100, 1024])\n","Final error of W quantization: 2.0579264163970947\n","\n","--------Results appended for cifar_resnet50_model.pt with precision 6\n","\n","--------Quantizing the model cifar_resnet50_model.pt with precision 4\n","All layers:  ['network.conv1.weight', 'network.bn1.weight', 'network.layer1.0.conv1.weight', 'network.layer1.0.bn1.weight', 'network.layer1.0.conv2.weight', 'network.layer1.0.bn2.weight', 'network.layer1.0.conv3.weight', 'network.layer1.0.bn3.weight', 'network.layer1.0.downsample.0.weight', 'network.layer1.0.downsample.1.weight', 'network.layer1.1.conv1.weight', 'network.layer1.1.bn1.weight', 'network.layer1.1.conv2.weight', 'network.layer1.1.bn2.weight', 'network.layer1.1.conv3.weight', 'network.layer1.1.bn3.weight', 'network.layer1.2.conv1.weight', 'network.layer1.2.bn1.weight', 'network.layer1.2.conv2.weight', 'network.layer1.2.bn2.weight', 'network.layer1.2.conv3.weight', 'network.layer1.2.bn3.weight', 'network.layer2.0.conv1.weight', 'network.layer2.0.bn1.weight', 'network.layer2.0.conv2.weight', 'network.layer2.0.bn2.weight', 'network.layer2.0.conv3.weight', 'network.layer2.0.bn3.weight', 'network.layer2.0.downsample.0.weight', 'network.layer2.0.downsample.1.weight', 'network.layer2.1.conv1.weight', 'network.layer2.1.bn1.weight', 'network.layer2.1.conv2.weight', 'network.layer2.1.bn2.weight', 'network.layer2.1.conv3.weight', 'network.layer2.1.bn3.weight', 'network.layer2.2.conv1.weight', 'network.layer2.2.bn1.weight', 'network.layer2.2.conv2.weight', 'network.layer2.2.bn2.weight', 'network.layer2.2.conv3.weight', 'network.layer2.2.bn3.weight', 'network.layer2.3.conv1.weight', 'network.layer2.3.bn1.weight', 'network.layer2.3.conv2.weight', 'network.layer2.3.bn2.weight', 'network.layer2.3.conv3.weight', 'network.layer2.3.bn3.weight', 'network.layer3.0.conv1.weight', 'network.layer3.0.bn1.weight', 'network.layer3.0.conv2.weight', 'network.layer3.0.bn2.weight', 'network.layer3.0.conv3.weight', 'network.layer3.0.bn3.weight', 'network.layer3.0.downsample.0.weight', 'network.layer3.0.downsample.1.weight', 'network.layer3.1.conv1.weight', 'network.layer3.1.bn1.weight', 'network.layer3.1.conv2.weight', 'network.layer3.1.bn2.weight', 'network.layer3.1.conv3.weight', 'network.layer3.1.bn3.weight', 'network.layer3.2.conv1.weight', 'network.layer3.2.bn1.weight', 'network.layer3.2.conv2.weight', 'network.layer3.2.bn2.weight', 'network.layer3.2.conv3.weight', 'network.layer3.2.bn3.weight', 'network.layer3.3.conv1.weight', 'network.layer3.3.bn1.weight', 'network.layer3.3.conv2.weight', 'network.layer3.3.bn2.weight', 'network.layer3.3.conv3.weight', 'network.layer3.3.bn3.weight', 'network.layer3.4.conv1.weight', 'network.layer3.4.bn1.weight', 'network.layer3.4.conv2.weight', 'network.layer3.4.bn2.weight', 'network.layer3.4.conv3.weight', 'network.layer3.4.bn3.weight', 'network.layer3.5.conv1.weight', 'network.layer3.5.bn1.weight', 'network.layer3.5.conv2.weight', 'network.layer3.5.bn2.weight', 'network.layer3.5.conv3.weight', 'network.layer3.5.bn3.weight', 'network.layer4.0.conv1.weight', 'network.layer4.0.bn1.weight', 'network.layer4.0.conv2.weight', 'network.layer4.0.bn2.weight', 'network.layer4.0.conv3.weight', 'network.layer4.0.bn3.weight', 'network.layer4.0.downsample.0.weight', 'network.layer4.0.downsample.1.weight', 'network.layer4.1.conv1.weight', 'network.layer4.1.bn1.weight', 'network.layer4.1.conv2.weight', 'network.layer4.1.bn2.weight', 'network.layer4.1.conv3.weight', 'network.layer4.1.bn3.weight', 'network.layer4.2.conv1.weight', 'network.layer4.2.bn1.weight', 'network.layer4.2.conv2.weight', 'network.layer4.2.bn2.weight', 'network.layer4.2.conv3.weight', 'network.layer4.2.bn3.weight', 'network.fc.0.weight', 'network.fc.2.weight']\n","\n","Quantizing layer:network.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.7657077312469482\n","\n","Quantizing layer:network.layer1.0.conv1.weight , with weights shape:torch.Size([64, 64, 1, 1])\n","Final error of W quantization: 3.429265260696411\n","\n","Quantizing layer:network.layer1.0.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.4465796947479248\n","\n","Quantizing layer:network.layer1.0.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 3.389183282852173\n","\n","Quantizing layer:network.layer1.0.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.221914291381836\n","\n","Quantizing layer:network.layer1.0.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 3.1264312267303467\n","\n","Quantizing layer:network.layer1.0.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.232396125793457\n","\n","Quantizing layer:network.layer1.0.downsample.0.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 3.028486728668213\n","\n","Quantizing layer:network.layer1.0.downsample.1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 3.2073395252227783\n","\n","Quantizing layer:network.layer1.1.conv1.weight , with weights shape:torch.Size([64, 256, 1, 1])\n","Final error of W quantization: 3.1429026126861572\n","\n","Quantizing layer:network.layer1.1.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.3802820444107056\n","\n","Quantizing layer:network.layer1.1.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 2.4245336055755615\n","\n","Quantizing layer:network.layer1.1.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.3221862316131592\n","\n","Quantizing layer:network.layer1.1.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 3.2520010471343994\n","\n","Quantizing layer:network.layer1.1.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.4785616397857666\n","\n","Quantizing layer:network.layer1.2.conv1.weight , with weights shape:torch.Size([64, 256, 1, 1])\n","Final error of W quantization: 3.443686008453369\n","\n","Quantizing layer:network.layer1.2.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.3472051620483398\n","\n","Quantizing layer:network.layer1.2.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 4.6651201248168945\n","\n","Quantizing layer:network.layer1.2.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.5786463022232056\n","\n","Quantizing layer:network.layer1.2.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 3.2835960388183594\n","\n","Quantizing layer:network.layer1.2.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.579074501991272\n","\n","Quantizing layer:network.layer2.0.conv1.weight , with weights shape:torch.Size([128, 256, 1, 1])\n","Final error of W quantization: 4.59185266494751\n","\n","Quantizing layer:network.layer2.0.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 2.0653817653656006\n","\n","Quantizing layer:network.layer2.0.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 6.541067123413086\n","\n","Quantizing layer:network.layer2.0.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 2.0718207359313965\n","\n","Quantizing layer:network.layer2.0.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 4.5064616203308105\n","\n","Quantizing layer:network.layer2.0.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.7378053665161133\n","\n","Quantizing layer:network.layer2.0.downsample.0.weight , with weights shape:torch.Size([512, 256, 1, 1])\n","Final error of W quantization: 3.905975580215454\n","\n","Quantizing layer:network.layer2.0.downsample.1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 3.0017495155334473\n","\n","Quantizing layer:network.layer2.1.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 3.0732882022857666\n","\n","Quantizing layer:network.layer2.1.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.2397809028625488\n","\n","Quantizing layer:network.layer2.1.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 4.851787567138672\n","\n","Quantizing layer:network.layer2.1.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.6890889406204224\n","\n","Quantizing layer:network.layer2.1.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 4.076278209686279\n","\n","Quantizing layer:network.layer2.1.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.4310054779052734\n","\n","Quantizing layer:network.layer2.2.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 4.80750036239624\n","\n","Quantizing layer:network.layer2.2.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.7883342504501343\n","\n","Quantizing layer:network.layer2.2.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 5.99484395980835\n","\n","Quantizing layer:network.layer2.2.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.9067636728286743\n","\n","Quantizing layer:network.layer2.2.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 4.286129474639893\n","\n","Quantizing layer:network.layer2.2.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.275913715362549\n","\n","Quantizing layer:network.layer2.3.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 4.429468154907227\n","\n","Quantizing layer:network.layer2.3.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.7661513090133667\n","\n","Quantizing layer:network.layer2.3.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 6.483068943023682\n","\n","Quantizing layer:network.layer2.3.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 2.1161623001098633\n","\n","Quantizing layer:network.layer2.3.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 4.260762691497803\n","\n","Quantizing layer:network.layer2.3.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.1171927452087402\n","\n","Quantizing layer:network.layer3.0.conv1.weight , with weights shape:torch.Size([256, 512, 1, 1])\n","Final error of W quantization: 7.5926995277404785\n","\n","Quantizing layer:network.layer3.0.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 3.348677158355713\n","\n","Quantizing layer:network.layer3.0.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 10.43416690826416\n","\n","Quantizing layer:network.layer3.0.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.556220531463623\n","\n","Quantizing layer:network.layer3.0.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 7.439266204833984\n","\n","Quantizing layer:network.layer3.0.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 4.152252197265625\n","\n","Quantizing layer:network.layer3.0.downsample.0.weight , with weights shape:torch.Size([1024, 512, 1, 1])\n","Final error of W quantization: 6.089883804321289\n","\n","Quantizing layer:network.layer3.0.downsample.1.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 3.394073009490967\n","\n","Quantizing layer:network.layer3.1.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 4.33513879776001\n","\n","Quantizing layer:network.layer3.1.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.2140817642211914\n","\n","Quantizing layer:network.layer3.1.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 7.063711643218994\n","\n","Quantizing layer:network.layer3.1.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.4953479766845703\n","\n","Quantizing layer:network.layer3.1.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 4.028901100158691\n","\n","Quantizing layer:network.layer3.1.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 2.7359578609466553\n","\n","Quantizing layer:network.layer3.2.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 5.04538631439209\n","\n","Quantizing layer:network.layer3.2.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.281893491744995\n","\n","Quantizing layer:network.layer3.2.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 8.415698051452637\n","\n","Quantizing layer:network.layer3.2.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.599318027496338\n","\n","Quantizing layer:network.layer3.2.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 5.537835597991943\n","\n","Quantizing layer:network.layer3.2.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 2.787614583969116\n","\n","Quantizing layer:network.layer3.3.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 5.93376350402832\n","\n","Quantizing layer:network.layer3.3.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.4241554737091064\n","\n","Quantizing layer:network.layer3.3.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 6.3538312911987305\n","\n","Quantizing layer:network.layer3.3.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.5281167030334473\n","\n","Quantizing layer:network.layer3.3.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 5.013559818267822\n","\n","Quantizing layer:network.layer3.3.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 2.7095587253570557\n","\n","Quantizing layer:network.layer3.4.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 5.898906230926514\n","\n","Quantizing layer:network.layer3.4.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.4456896781921387\n","\n","Quantizing layer:network.layer3.4.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 8.479066848754883\n","\n","Quantizing layer:network.layer3.4.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.6080479621887207\n","\n","Quantizing layer:network.layer3.4.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 4.991937637329102\n","\n","Quantizing layer:network.layer3.4.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 2.956270933151245\n","\n","Quantizing layer:network.layer3.5.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 3.9464304447174072\n","\n","Quantizing layer:network.layer3.5.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.6643409729003906\n","\n","Quantizing layer:network.layer3.5.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 7.542715549468994\n","\n","Quantizing layer:network.layer3.5.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.320380687713623\n","\n","Quantizing layer:network.layer3.5.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 5.9248270988464355\n","\n","Quantizing layer:network.layer3.5.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 3.1943185329437256\n","\n","Quantizing layer:network.layer4.0.conv1.weight , with weights shape:torch.Size([512, 1024, 1, 1])\n","Final error of W quantization: 9.693395614624023\n","\n","Quantizing layer:network.layer4.0.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.526162624359131\n","\n","Quantizing layer:network.layer4.0.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 3.6249659061431885\n","\n","Quantizing layer:network.layer4.0.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 3.9559075832366943\n","\n","Quantizing layer:network.layer4.0.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 6.20167875289917\n","\n","Quantizing layer:network.layer4.0.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 12.838022232055664\n","\n","Quantizing layer:network.layer4.0.downsample.0.weight , with weights shape:torch.Size([2048, 1024, 1, 1])\n","Final error of W quantization: 1.823946237564087\n","\n","Quantizing layer:network.layer4.0.downsample.1.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 6.677535057067871\n","\n","Quantizing layer:network.layer4.1.conv1.weight , with weights shape:torch.Size([512, 2048, 1, 1])\n","Final error of W quantization: 1.2770888805389404\n","\n","Quantizing layer:network.layer4.1.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 3.9464237689971924\n","\n","Quantizing layer:network.layer4.1.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 11.975414276123047\n","\n","Quantizing layer:network.layer4.1.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.232822418212891\n","\n","Quantizing layer:network.layer4.1.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 9.124911308288574\n","\n","Quantizing layer:network.layer4.1.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 11.548973083496094\n","\n","Quantizing layer:network.layer4.2.conv1.weight , with weights shape:torch.Size([512, 2048, 1, 1])\n","Final error of W quantization: 6.302295684814453\n","\n","Quantizing layer:network.layer4.2.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 3.8713526725769043\n","\n","Quantizing layer:network.layer4.2.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 14.987658500671387\n","\n","Quantizing layer:network.layer4.2.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.233587265014648\n","\n","Quantizing layer:network.layer4.2.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 8.008831977844238\n","\n","Quantizing layer:network.layer4.2.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 18.413610458374023\n","\n","Quantizing layer:network.fc.0.weight , with weights shape:torch.Size([1024, 2048])\n","Final error of W quantization: 22.83692169189453\n","\n","Quantizing layer:network.fc.2.weight , with weights shape:torch.Size([100, 1024])\n","Final error of W quantization: 6.102115631103516\n","\n","--------Results appended for cifar_resnet50_model.pt with precision 4\n","\n","--------Quantizing the model cifar_resnet50_model.pt with precision 2\n","All layers:  ['network.conv1.weight', 'network.bn1.weight', 'network.layer1.0.conv1.weight', 'network.layer1.0.bn1.weight', 'network.layer1.0.conv2.weight', 'network.layer1.0.bn2.weight', 'network.layer1.0.conv3.weight', 'network.layer1.0.bn3.weight', 'network.layer1.0.downsample.0.weight', 'network.layer1.0.downsample.1.weight', 'network.layer1.1.conv1.weight', 'network.layer1.1.bn1.weight', 'network.layer1.1.conv2.weight', 'network.layer1.1.bn2.weight', 'network.layer1.1.conv3.weight', 'network.layer1.1.bn3.weight', 'network.layer1.2.conv1.weight', 'network.layer1.2.bn1.weight', 'network.layer1.2.conv2.weight', 'network.layer1.2.bn2.weight', 'network.layer1.2.conv3.weight', 'network.layer1.2.bn3.weight', 'network.layer2.0.conv1.weight', 'network.layer2.0.bn1.weight', 'network.layer2.0.conv2.weight', 'network.layer2.0.bn2.weight', 'network.layer2.0.conv3.weight', 'network.layer2.0.bn3.weight', 'network.layer2.0.downsample.0.weight', 'network.layer2.0.downsample.1.weight', 'network.layer2.1.conv1.weight', 'network.layer2.1.bn1.weight', 'network.layer2.1.conv2.weight', 'network.layer2.1.bn2.weight', 'network.layer2.1.conv3.weight', 'network.layer2.1.bn3.weight', 'network.layer2.2.conv1.weight', 'network.layer2.2.bn1.weight', 'network.layer2.2.conv2.weight', 'network.layer2.2.bn2.weight', 'network.layer2.2.conv3.weight', 'network.layer2.2.bn3.weight', 'network.layer2.3.conv1.weight', 'network.layer2.3.bn1.weight', 'network.layer2.3.conv2.weight', 'network.layer2.3.bn2.weight', 'network.layer2.3.conv3.weight', 'network.layer2.3.bn3.weight', 'network.layer3.0.conv1.weight', 'network.layer3.0.bn1.weight', 'network.layer3.0.conv2.weight', 'network.layer3.0.bn2.weight', 'network.layer3.0.conv3.weight', 'network.layer3.0.bn3.weight', 'network.layer3.0.downsample.0.weight', 'network.layer3.0.downsample.1.weight', 'network.layer3.1.conv1.weight', 'network.layer3.1.bn1.weight', 'network.layer3.1.conv2.weight', 'network.layer3.1.bn2.weight', 'network.layer3.1.conv3.weight', 'network.layer3.1.bn3.weight', 'network.layer3.2.conv1.weight', 'network.layer3.2.bn1.weight', 'network.layer3.2.conv2.weight', 'network.layer3.2.bn2.weight', 'network.layer3.2.conv3.weight', 'network.layer3.2.bn3.weight', 'network.layer3.3.conv1.weight', 'network.layer3.3.bn1.weight', 'network.layer3.3.conv2.weight', 'network.layer3.3.bn2.weight', 'network.layer3.3.conv3.weight', 'network.layer3.3.bn3.weight', 'network.layer3.4.conv1.weight', 'network.layer3.4.bn1.weight', 'network.layer3.4.conv2.weight', 'network.layer3.4.bn2.weight', 'network.layer3.4.conv3.weight', 'network.layer3.4.bn3.weight', 'network.layer3.5.conv1.weight', 'network.layer3.5.bn1.weight', 'network.layer3.5.conv2.weight', 'network.layer3.5.bn2.weight', 'network.layer3.5.conv3.weight', 'network.layer3.5.bn3.weight', 'network.layer4.0.conv1.weight', 'network.layer4.0.bn1.weight', 'network.layer4.0.conv2.weight', 'network.layer4.0.bn2.weight', 'network.layer4.0.conv3.weight', 'network.layer4.0.bn3.weight', 'network.layer4.0.downsample.0.weight', 'network.layer4.0.downsample.1.weight', 'network.layer4.1.conv1.weight', 'network.layer4.1.bn1.weight', 'network.layer4.1.conv2.weight', 'network.layer4.1.bn2.weight', 'network.layer4.1.conv3.weight', 'network.layer4.1.bn3.weight', 'network.layer4.2.conv1.weight', 'network.layer4.2.bn1.weight', 'network.layer4.2.conv2.weight', 'network.layer4.2.bn2.weight', 'network.layer4.2.conv3.weight', 'network.layer4.2.bn3.weight', 'network.fc.0.weight', 'network.fc.2.weight']\n","\n","Quantizing layer:network.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 2.1019489765167236\n","\n","Quantizing layer:network.layer1.0.conv1.weight , with weights shape:torch.Size([64, 64, 1, 1])\n","Final error of W quantization: 4.380486011505127\n","\n","Quantizing layer:network.layer1.0.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.6426767110824585\n","\n","Quantizing layer:network.layer1.0.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 5.316605567932129\n","\n","Quantizing layer:network.layer1.0.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.3299473524093628\n","\n","Quantizing layer:network.layer1.0.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 4.342836380004883\n","\n","Quantizing layer:network.layer1.0.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.5713582038879395\n","\n","Quantizing layer:network.layer1.0.downsample.0.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 6.62148904800415\n","\n","Quantizing layer:network.layer1.0.downsample.1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 3.767461061477661\n","\n","Quantizing layer:network.layer1.1.conv1.weight , with weights shape:torch.Size([64, 256, 1, 1])\n","Final error of W quantization: 3.7955968379974365\n","\n","Quantizing layer:network.layer1.1.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.5466563701629639\n","\n","Quantizing layer:network.layer1.1.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 4.791891574859619\n","\n","Quantizing layer:network.layer1.1.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.4780728816986084\n","\n","Quantizing layer:network.layer1.1.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 4.034782886505127\n","\n","Quantizing layer:network.layer1.1.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.619234323501587\n","\n","Quantizing layer:network.layer1.2.conv1.weight , with weights shape:torch.Size([64, 256, 1, 1])\n","Final error of W quantization: 3.765669107437134\n","\n","Quantizing layer:network.layer1.2.bn1.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.4590798616409302\n","\n","Quantizing layer:network.layer1.2.conv2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 5.866343975067139\n","\n","Quantizing layer:network.layer1.2.bn2.weight , with weights shape:torch.Size([64])\n","Final error of W quantization: 1.7618052959442139\n","\n","Quantizing layer:network.layer1.2.conv3.weight , with weights shape:torch.Size([256, 64, 1, 1])\n","Final error of W quantization: 3.872548818588257\n","\n","Quantizing layer:network.layer1.2.bn3.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 1.8115447759628296\n","\n","Quantizing layer:network.layer2.0.conv1.weight , with weights shape:torch.Size([128, 256, 1, 1])\n","Final error of W quantization: 6.16050910949707\n","\n","Quantizing layer:network.layer2.0.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 2.3308448791503906\n","\n","Quantizing layer:network.layer2.0.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 8.293911933898926\n","\n","Quantizing layer:network.layer2.0.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 2.2755494117736816\n","\n","Quantizing layer:network.layer2.0.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 6.83709192276001\n","\n","Quantizing layer:network.layer2.0.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 3.0563066005706787\n","\n","Quantizing layer:network.layer2.0.downsample.0.weight , with weights shape:torch.Size([512, 256, 1, 1])\n","Final error of W quantization: 7.142024993896484\n","\n","Quantizing layer:network.layer2.0.downsample.1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 3.439511299133301\n","\n","Quantizing layer:network.layer2.1.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 4.045322895050049\n","\n","Quantizing layer:network.layer2.1.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.3400620222091675\n","\n","Quantizing layer:network.layer2.1.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 7.010778903961182\n","\n","Quantizing layer:network.layer2.1.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.8636269569396973\n","\n","Quantizing layer:network.layer2.1.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 5.410201549530029\n","\n","Quantizing layer:network.layer2.1.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.76556134223938\n","\n","Quantizing layer:network.layer2.2.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 5.77859354019165\n","\n","Quantizing layer:network.layer2.2.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.939911127090454\n","\n","Quantizing layer:network.layer2.2.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 7.8940935134887695\n","\n","Quantizing layer:network.layer2.2.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 2.0679080486297607\n","\n","Quantizing layer:network.layer2.2.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 6.340801239013672\n","\n","Quantizing layer:network.layer2.2.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.6261138916015625\n","\n","Quantizing layer:network.layer2.3.conv1.weight , with weights shape:torch.Size([128, 512, 1, 1])\n","Final error of W quantization: 5.924138069152832\n","\n","Quantizing layer:network.layer2.3.bn1.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 1.9181560277938843\n","\n","Quantizing layer:network.layer2.3.conv2.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 8.24097728729248\n","\n","Quantizing layer:network.layer2.3.bn2.weight , with weights shape:torch.Size([128])\n","Final error of W quantization: 2.2876837253570557\n","\n","Quantizing layer:network.layer2.3.conv3.weight , with weights shape:torch.Size([512, 128, 1, 1])\n","Final error of W quantization: 5.934591293334961\n","\n","Quantizing layer:network.layer2.3.bn3.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 2.416996479034424\n","\n","Quantizing layer:network.layer3.0.conv1.weight , with weights shape:torch.Size([256, 512, 1, 1])\n","Final error of W quantization: 10.639781951904297\n","\n","Quantizing layer:network.layer3.0.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 3.7219738960266113\n","\n","Quantizing layer:network.layer3.0.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 12.70447826385498\n","\n","Quantizing layer:network.layer3.0.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.8976686000823975\n","\n","Quantizing layer:network.layer3.0.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 11.303579330444336\n","\n","Quantizing layer:network.layer3.0.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 4.7508625984191895\n","\n","Quantizing layer:network.layer3.0.downsample.0.weight , with weights shape:torch.Size([1024, 512, 1, 1])\n","Final error of W quantization: 10.733642578125\n","\n","Quantizing layer:network.layer3.0.downsample.1.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 3.8620710372924805\n","\n","Quantizing layer:network.layer3.1.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 7.201797008514404\n","\n","Quantizing layer:network.layer3.1.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.510556221008301\n","\n","Quantizing layer:network.layer3.1.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 10.761289596557617\n","\n","Quantizing layer:network.layer3.1.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.9921462535858154\n","\n","Quantizing layer:network.layer3.1.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 9.525129318237305\n","\n","Quantizing layer:network.layer3.1.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 3.499290704727173\n","\n","Quantizing layer:network.layer3.2.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 7.506687641143799\n","\n","Quantizing layer:network.layer3.2.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.4866843223571777\n","\n","Quantizing layer:network.layer3.2.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 10.843605995178223\n","\n","Quantizing layer:network.layer3.2.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.938782215118408\n","\n","Quantizing layer:network.layer3.2.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 9.127959251403809\n","\n","Quantizing layer:network.layer3.2.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 3.1064319610595703\n","\n","Quantizing layer:network.layer3.3.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 8.371550559997559\n","\n","Quantizing layer:network.layer3.3.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.63786244392395\n","\n","Quantizing layer:network.layer3.3.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 10.546402931213379\n","\n","Quantizing layer:network.layer3.3.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.7541592121124268\n","\n","Quantizing layer:network.layer3.3.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 8.675345420837402\n","\n","Quantizing layer:network.layer3.3.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 3.123070001602173\n","\n","Quantizing layer:network.layer3.4.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 8.689684867858887\n","\n","Quantizing layer:network.layer3.4.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.672734498977661\n","\n","Quantizing layer:network.layer3.4.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 10.796916961669922\n","\n","Quantizing layer:network.layer3.4.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.836662769317627\n","\n","Quantizing layer:network.layer3.4.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 8.658207893371582\n","\n","Quantizing layer:network.layer3.4.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 3.2570133209228516\n","\n","Quantizing layer:network.layer3.5.conv1.weight , with weights shape:torch.Size([256, 1024, 1, 1])\n","Final error of W quantization: 9.220240592956543\n","\n","Quantizing layer:network.layer3.5.bn1.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 2.9436709880828857\n","\n","Quantizing layer:network.layer3.5.conv2.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 11.004654884338379\n","\n","Quantizing layer:network.layer3.5.bn2.weight , with weights shape:torch.Size([256])\n","Final error of W quantization: 3.0193700790405273\n","\n","Quantizing layer:network.layer3.5.conv3.weight , with weights shape:torch.Size([1024, 256, 1, 1])\n","Final error of W quantization: 9.337414741516113\n","\n","Quantizing layer:network.layer3.5.bn3.weight , with weights shape:torch.Size([1024])\n","Final error of W quantization: 3.6756842136383057\n","\n","Quantizing layer:network.layer4.0.conv1.weight , with weights shape:torch.Size([512, 1024, 1, 1])\n","Final error of W quantization: 16.16733741760254\n","\n","Quantizing layer:network.layer4.0.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.955545902252197\n","\n","Quantizing layer:network.layer4.0.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 16.625873565673828\n","\n","Quantizing layer:network.layer4.0.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.387332916259766\n","\n","Quantizing layer:network.layer4.0.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 14.102331161499023\n","\n","Quantizing layer:network.layer4.0.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 16.128379821777344\n","\n","Quantizing layer:network.layer4.0.downsample.0.weight , with weights shape:torch.Size([2048, 1024, 1, 1])\n","Final error of W quantization: 7.988790035247803\n","\n","Quantizing layer:network.layer4.0.downsample.1.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 11.96304702758789\n","\n","Quantizing layer:network.layer4.1.conv1.weight , with weights shape:torch.Size([512, 2048, 1, 1])\n","Final error of W quantization: 9.558960914611816\n","\n","Quantizing layer:network.layer4.1.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.3505988121032715\n","\n","Quantizing layer:network.layer4.1.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 17.75094223022461\n","\n","Quantizing layer:network.layer4.1.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.709174156188965\n","\n","Quantizing layer:network.layer4.1.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 14.22027587890625\n","\n","Quantizing layer:network.layer4.1.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 16.030593872070312\n","\n","Quantizing layer:network.layer4.2.conv1.weight , with weights shape:torch.Size([512, 2048, 1, 1])\n","Final error of W quantization: 17.093833923339844\n","\n","Quantizing layer:network.layer4.2.bn1.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.854555130004883\n","\n","Quantizing layer:network.layer4.2.conv2.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 16.376811981201172\n","\n","Quantizing layer:network.layer4.2.bn2.weight , with weights shape:torch.Size([512])\n","Final error of W quantization: 4.7556681632995605\n","\n","Quantizing layer:network.layer4.2.conv3.weight , with weights shape:torch.Size([2048, 512, 1, 1])\n","Final error of W quantization: 13.299789428710938\n","\n","Quantizing layer:network.layer4.2.bn3.weight , with weights shape:torch.Size([2048])\n","Final error of W quantization: 31.534496307373047\n","\n","Quantizing layer:network.fc.0.weight , with weights shape:torch.Size([1024, 2048])\n","Final error of W quantization: 34.560150146484375\n","\n","Quantizing layer:network.fc.2.weight , with weights shape:torch.Size([100, 1024])\n","Final error of W quantization: 8.756842613220215\n","\n","--------Results appended for cifar_resnet50_model.pt with precision 2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44d86609934c44ed99467a35d1b84cad","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98f568eca51e4742ab208122e20be751","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Train Accuracy:  0.54642  Test Accuracy:  0.5029\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"432a0766346443868154bddd7a3351ba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbed456b67f54a8c960d6d9f0ded9e5f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Train Accuracy:  0.553  Test Accuracy:  0.5137\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88d762f810684c008b6e04292a88e11f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b944d0c1aaa84e1c9954522f80eb3717","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Train Accuracy:  0.01  Test Accuracy:  0.01\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2bbae422112a4f068c6e711ee8c2d694","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6509e3ba55a4a0683414c65c45c7914","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Train Accuracy:  0.01  Test Accuracy:  0.01\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43ff4da758b742679d68c52c5701004e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c85ee8b3eb348d396ab6c81e5388cc1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Train Accuracy:  0.01  Test Accuracy:  0.01\n","                     model quant_method  ... test_loss test_acc\n","0  cifar_resnet50_model.pt  multi-point  ...  1.780089   0.5029\n","1  cifar_resnet50_model.pt  multi-point  ...  1.740885   0.5137\n","2  cifar_resnet50_model.pt  multi-point  ...  5.101506   0.0100\n","3  cifar_resnet50_model.pt  multi-point  ...  4.611042   0.0100\n","4  cifar_resnet50_model.pt  multi-point  ...  4.610587   0.0100\n","\n","[5 rows x 8 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5FCl4rWW6wFx"},"source":["# **Model = VGG16, Data= CIFAR100**\n","Val Accuracy=19%"]},{"cell_type":"code","metadata":{"id":"Wo9Cn9BU68ih","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a5279ad6a4f14f8b84fdc378e4cce724","632635c4ef50451c9a846d44dab8155f","3415351a2f704a4e9c74b022efb0aec0","0a9c31190f02410896a611cad28a2421","f4c5c52994c9420ca079a4c757885a4d","b1d934c7bb4849e2a5fc89a4ccedb292","57f2bb9c9a3e45bb9ea16fc565aedae7","1ad998429b9f4a428608014a7c858d61","dbe371b07b954861847ee82f4a9c9bd5","cb0db3dee137408f89f5fbdf2aa881ff","ff9460b09bdd48929c372028e0a0604b","96a190535f644e63a679eb1649779c14","ea8d8a772eb64dc5b103fde0d356245d","a01bea565ecc4aa8a0301dabec296ecf","913d8553ee0642b38bb0e48ae2a42f32","ac188bef39a444298fc89ee77272bd60","74806d17d4b04e11881c0b783af45ede","6bd8024bdc5a452a8babf066bca1b0d0","0509c0ce140b494da8dfd494fd2b608c","f47a6675e4b94fccb6d9b3eb20ea0599","89e75f1b8d49405492d7a4f0210d7fe1","1860cfe71eef467081d63ac084979024","c87344bfaea74ca7befca4da819208e1","b745fa956fbb48d987737cdb12896c17","d9dbcaed59e348d88105628af83231ca","7bed0049f6764eea8d593c63b45ee434","e86008d281e04f93ae1f03cb9edc7c8b","62cfaf10cbb84c71b4c91583354bf599","b204169035874379aee1e4a474bb7d56","af83bae4f0194b1093b50266ce794448","b164a8b97ba74a50af908331530909cd","0ccd174d21d049d48af0f2436d9aed9c","c4176c0a0e564434a728ceb23bc48643","a62a5504815b4524a0d2a5a2b9fcf8ce","43a6f106f9a145b7851ca14ccb78b74e","aef7a8ff0539499190179d9c1789ff62","dd5e5cc586a441d0bcf33242e0534220","566c51e6ca5d49b7913ab01efef067a5","5b56169d000448f6a552c360946945e9","7d1aa42b7e9643feae31f86a3e6a75cb"]},"executionInfo":{"status":"ok","timestamp":1605859183542,"user_tz":480,"elapsed":401824,"user":{"displayName":"Kumari Nishu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFdfS8IitH2P71X64Sf8cglHIG79P672a7SbQD=s64","userId":"13793804378645653224"}},"outputId":"d2a25e55-2924-4e67-b072-3d485dc438d2"},"source":["# %%writefile train_cifar.py\n","import time\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchsummary import summary\n","\n","from model.dnn import DenseNeuralNet\n","from model.cnn import CNN_vgg16\n","from utils.post_training_quantization import *\n","from data.mv_data import MVDataset\n","from tqdm.auto import trange, tqdm\n","from tqdm import trange\n","from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","\n","\n","def get_cifar100_dataset(train = True):\n","  transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","  ])\n","\n","  transform_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","  ])\n","\n","  if train == True:\n","      dataset = datasets.CIFAR100(root = './data', train = train, transform=transform_test, target_transform=None, download=True)\n","  else:\n","      dataset = datasets.CIFAR100(root = './data', train = train, transform=transform_test, target_transform=None, download=True)\n","  \n","  return dataset\n","\n","\n","def get_accuracy(logits, labels):\n","  preds = torch.argmax(logits, axis=1)\n","  matches = preds == labels\n","  return (matches.sum(), len(labels))\n","\n","\n","def evaluate(model, test_set, batch_size, criterion, ep = 0):\n","  test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, shuffle=True, num_workers=1)\n","  test_iterator = tqdm(test_loader, desc = 'Eval Iteration for epoch:'+str(ep+1), ncols = 900)\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  \n","  model.eval()\n","  global_step = 0\n","  total_correct = 0\n","  total_samples = 0\n","  total_loss = 0.0\n","  with torch.no_grad():\n","    for step, inputs in enumerate(test_iterator):\n","      global_step +=1\n","      # if global_step > 500:\n","      #   break\n","      x, y = inputs[0].to(device), inputs[1].long().to(device)\n","\n","      logits = model(x)\n","      loss = criterion(logits, y)\n","      correct, samples = get_accuracy(logits, y)\n","      total_correct +=correct.item()\n","      total_samples +=samples\n","      total_loss +=loss\n","  # print(total_correct, total_samples)\n","  acc = total_correct / total_samples\n","  total_loss = total_loss / global_step\n","  model.train()\n","  \n","  return (total_loss, acc)\n","\n","\n","def train(model, train_set, val_set, test_set , batch_size = 16, learning_rate = 0.03, epochs = 5, eval_steps = 10, skip_train_set = True):\n","  # logging\n","  train_log = open(\"log/cifar_vgg16_train.log\", \"a\")\n","  val_log = open(\"log/cifar_vgg16_val.log\", \"a\")\n","  test_log = open(\"log/cifar_vgg16_test.log\", \"a\")\n","\n","  # GPU/CPU use\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(\"Device: \", device)\n","  model = model.to(device)\n","  print(\"Model Summary:\")\n","  summary(model, next(iter(train_set))[0].shape)\n","  \n","  # define loss & optimizer\n","  criterion = nn.CrossEntropyLoss()\n","  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-6, momentum=0.9, nesterov=True)\n","\n","  # iterate over epoch\n","  train_loader = torch.utils.data.DataLoader(dataset= train_set, batch_size=batch_size, shuffle=True, num_workers=1)\n","  global_step = 0\n","  for ep in tqdm(range(epochs), desc = ' Epoch Progress:', ncols=900):\n","    train_iterator = tqdm(train_loader, desc = 'Train Iteration for epoch:'+ str(ep+1), ncols=900)    \n","    running_loss = 0\n","\n","    # iterate over batches\n","    for step, inputs in enumerate(train_iterator):\n","      model.train()\n","      global_step +=1\n","      optimizer.zero_grad()\n","      # predict, find loss, get grads, update weight\n","      x, y = inputs[0].to(device), inputs[1].to(device)\n","      logits = model(x)\n","      loss = criterion(logits, y)\n","      loss.backward()\n","      optimizer.step()\n","      running_loss+=loss.item()\n","\n","    # find validation accuracy\n","    val_loss, val_accuracy = evaluate(model, val_set, batch_size, criterion, ep)\n","    val_log.write(\"Epoch = {}, validation loss =  {}, validation accuracy = {} \\n\".format(ep+1, val_loss, val_accuracy))\n","    print(\"Step = %d, validation loss =  %.3f, validation accuracy = %.3f\" %(global_step, val_loss, val_accuracy))\n","    \n","    # find train accuracy if needed\n","    if not skip_train_set:\n","      train_loss , train_accuracy = evaluate(model, train_set, batch_size, criterion, ep)\n","      train_log.write(\"Epoch = {}, training loss =  {}, training accuracy = {} \\n\".format(ep+1, train_loss, train_accuracy))\n","      print(\"Step = %d, training loss =  %.3f, training accuracy = %.3f\" %(global_step, train_loss, train_accuracy))\n","\n","  # find test accuracy with final model\n","  if test_set is not None:  \n","    test_loss, test_accuracy = evaluate(model, test_set, batch_size, criterion, ep)\n","    test_log.write(\"End of training, test loss =  {}, test accuracy = {} \\n\".format(test_loss, test_accuracy))\n","    print(\"End of Training, test loss =  %.3f, test accuracy = %.3f\" %(test_loss, test_accuracy))\n","\n","  # close log files\n","  train_log.close()\n","  val_log.close()\n","  test_log.close()\n","\n","def main(train_model, quantize):\n","  ### config params\n","  output_classes = 100\n","  learning_rate = 0.01\n","  batch_size = 32\n","  epochs = 10\n","  eval_steps = 100\n","  model_dir = 'model_artifacts'\n","  model_name = 'cifar_vgg16_model.pt'\n","  criterion = nn.CrossEntropyLoss()\n","  ####\n","\n","  train_set, val_set, test_set = None, None, None\n","  train_set = get_cifar100_dataset(train = True)\n","  val_set = get_cifar100_dataset(train = False)\n","\n","  if train_model:\n","    model = CNN_vgg16(output_classes)\n","    train(model, train_set, val_set, test_set , batch_size = batch_size, learning_rate = learning_rate, epochs = epochs, eval_steps = eval_steps, skip_train_set = True)\n","    torch.save(model, os.path.join(model_dir, model_name))\n","  else:\n","    model = torch.load(os.path.join(model_dir, model_name))\n","    val_loss, val_accuracy = evaluate(model, val_set, batch_size, criterion)\n","    print(\"Running evaluation on loaded model, validation loss = %f, validation accuracy = %f\"%(val_loss, val_accuracy))\n","\n","\n","  if quantize:\n","    path_result = \"data/results/multipoint/\"\n","    # Choose Quantization method\n","    results = multipoint_quantization.multipoint_quantization(model_name, precision=[2])\n","    # results = quantization(model_name, method='all')\n","\n","    # Evaluate quantized models\n","    model_results = quantization_eval_results(results,train_set,val_set,batch_size,criterion)\n","    model_results.to_csv(path_result + model_name[:-3]+'_multipoint2' +\".csv\")\n","    print(model_results)\n","\n","\n","if __name__ == \"__main__\":\n","  main(train_model=False, quantize=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5279ad6a4f14f8b84fdc378e4cce724","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Running evaluation on loaded model, validation loss = 4.429444, validation accuracy = 0.193200\n","\n","--------Quantizing the model cifar_vgg16_model.pt with precision 2\n","All layers except bias layers:  ['network.features.0.weight', 'network.features.2.weight', 'network.features.5.weight', 'network.features.7.weight', 'network.features.10.weight', 'network.features.12.weight', 'network.features.14.weight', 'network.features.17.weight', 'network.features.19.weight', 'network.features.21.weight', 'network.features.24.weight', 'network.features.26.weight', 'network.features.28.weight', 'network.classifier.1.weight', 'network.classifier.4.weight', 'network.classifier.6.weight']\n","\n","Quantizing layer:network.features.2.weight , with weights shape:torch.Size([64, 64, 3, 3])\n","Final error of W quantization: 9.936873435974121\n","\n","Quantizing layer:network.features.5.weight , with weights shape:torch.Size([128, 64, 3, 3])\n","Final error of W quantization: 12.469865798950195\n","\n","Quantizing layer:network.features.7.weight , with weights shape:torch.Size([128, 128, 3, 3])\n","Final error of W quantization: 14.191423416137695\n","\n","Quantizing layer:network.features.10.weight , with weights shape:torch.Size([256, 128, 3, 3])\n","Final error of W quantization: 14.661410331726074\n","\n","Quantizing layer:network.features.12.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 17.569055557250977\n","\n","Quantizing layer:network.features.14.weight , with weights shape:torch.Size([256, 256, 3, 3])\n","Final error of W quantization: 15.675763130187988\n","\n","Quantizing layer:network.features.17.weight , with weights shape:torch.Size([512, 256, 3, 3])\n","Final error of W quantization: 21.29918098449707\n","\n","Quantizing layer:network.features.19.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 23.753507614135742\n","\n","Quantizing layer:network.features.21.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 23.560253143310547\n","\n","Quantizing layer:network.features.24.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 24.465450286865234\n","\n","Quantizing layer:network.features.26.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 25.14473533630371\n","\n","Quantizing layer:network.features.28.weight , with weights shape:torch.Size([512, 512, 3, 3])\n","Final error of W quantization: 23.79633903503418\n","\n","Quantizing layer:network.classifier.1.weight , with weights shape:torch.Size([4096, 25088])\n","Final error of W quantization: 37.222469329833984\n","\n","Quantizing layer:network.classifier.4.weight , with weights shape:torch.Size([256, 4096])\n","Final error of W quantization: 10.647074699401855\n","\n","Quantizing layer:network.classifier.6.weight , with weights shape:torch.Size([100, 256])\n","Final error of W quantization: 7.330192565917969\n","--------Results appended for cifar_vgg16_model.pt with precision 2\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbe371b07b954861847ee82f4a9c9bd5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74806d17d4b04e11881c0b783af45ede","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9dbcaed59e348d88105628af83231ca","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4176c0a0e564434a728ceb23bc48643","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Eval Iteration for epoch:1', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","                  model quant_method precision  ... train_acc  test_loss  test_acc\n","0  cifar_vgg16_model.pt  multi-point        32  ...    0.2143   4.429543    0.1932\n","1  cifar_vgg16_model.pt  multi-point         2  ...    0.0100   4.605170    0.0100\n","\n","[2 rows x 8 columns]\n"],"name":"stdout"}]}]}